<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home ¬∑ HDF5.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://JuliaIO.github.io/HDF5.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><script src="../copy.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.svg" alt="HDF5.jl logo"/></a><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Opening-and-closing-files"><span>Opening and closing files</span></a></li><li><a class="tocitem" href="#Writing-a-group-or-dataset"><span>Writing a group or dataset</span></a></li><li><a class="tocitem" href="#Opening-and-closing-objects"><span>Opening and closing objects</span></a></li><li><a class="tocitem" href="#Reading-and-writing-data"><span>Reading and writing data</span></a></li><li><a class="tocitem" href="#Passing-parameters"><span>Passing parameters</span></a></li><li><a class="tocitem" href="#Chunking-and-compression"><span>Chunking and compression</span></a></li><li><a class="tocitem" href="#Memory-mapping"><span>Memory mapping</span></a></li><li><a class="tocitem" href="#Supported-data-types"><span>Supported data types</span></a></li><li><a class="tocitem" href="#Creating-groups-and-attributes"><span>Creating groups and attributes</span></a></li><li><a class="tocitem" href="#Getting-information"><span>Getting information</span></a></li><li><a class="tocitem" href="#Mid-level-routines"><span>Mid-level routines</span></a></li><li><a class="tocitem" href="#Low-level-routines"><span>Low-level routines</span></a></li><li><a class="tocitem" href="#Parallel-HDF5"><span>Parallel HDF5</span></a></li><li><a class="tocitem" href="#Language-interoperability-with-row-and-column-major-order-arrays"><span>Language interoperability with row- and column-major order arrays</span></a></li><li><a class="tocitem" href="#Credits"><span>Credits</span></a></li><li class="toplevel"><a class="tocitem" href="#API-Reference"><span>API Reference</span></a></li></ul></li><li><span class="tocitem">Interface</span><ul><li><a class="tocitem" href="dataset/">Dataset</a></li><li><a class="tocitem" href="properties/">Properties</a></li><li><a class="tocitem" href="filters/">Filters</a></li></ul></li><li><a class="tocitem" href="api_bindings/">Low-level library bindings</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaIO/HDF5.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab">ÔÇõ</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="HDF5.jl"><a class="docs-heading-anchor" href="#HDF5.jl">HDF5.jl</a><a id="HDF5.jl-1"></a><a class="docs-heading-anchor-permalink" href="#HDF5.jl" title="Permalink"></a></h1><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p><a href="https://www.hdfgroup.org/solutions/hdf5/">HDF5</a> stands for Hierarchical Data Format v5 and is closely modeled on file systems. In HDF5, a &quot;group&quot; is analogous to a directory, a &quot;dataset&quot; is like a file. HDF5 also uses &quot;attributes&quot; to associate metadata with a particular group or dataset. HDF5 uses ASCII names for these different objects, and objects can be accessed by Unix-like pathnames, e.g., &quot;/sample1/tempsensor/firsttrial&quot; for a top-level group &quot;sample1&quot;, a subgroup &quot;tempsensor&quot;, and a dataset &quot;firsttrial&quot;.</p><p>For simple types (scalars, strings, and arrays), HDF5 provides sufficient metadata to know how each item is to be interpreted. For example, HDF5 encodes that a given block of bytes is to be interpreted as an array of <code>Int64</code>, and represents them in a way that is compatible across different computing architectures.</p><p>However, to preserve Julia objects, one generally needs additional type information to be supplied, which is easy to provide using attributes. This is handled for you automatically in the <a href="https://github.com/JuliaIO/JLD.jl">JLD</a>/<a href="https://github.com/JuliaIO/JLD2.jl">JLD2</a>. These specific formats (conventions) provide &quot;extra&quot; functionality, but they are still both regular HDF5 files and are therefore compatible with any HDF5 reader or writer.</p><p>Language wrappers for HDF5 are often described as either &quot;low level&quot; or &quot;high level.&quot; This package contains both flavors: at the low level, it directly wraps HDF5&#39;s functions, thus copying their API and making them available from within Julia. At the high level, it provides a set of functions built on the low-level wrap which may make the usage of this library more convenient.</p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><pre><code class="language-julia hljs">julia&gt;]
pkg&gt; add HDF5</code></pre><p>Starting from Julia 1.3, the HDF5 binaries are by default downloaded using the <code>HDF5_jll</code> package.</p><h3 id="Using-custom-or-system-provided-HDF5-binaries"><a class="docs-heading-anchor" href="#Using-custom-or-system-provided-HDF5-binaries">Using custom or system provided HDF5 binaries</a><a id="Using-custom-or-system-provided-HDF5-binaries-1"></a><a class="docs-heading-anchor-permalink" href="#Using-custom-or-system-provided-HDF5-binaries" title="Permalink"></a></h3><p>To use system-provided HDF5 binaries instead, set the environment variable <code>JULIA_HDF5_PATH</code> to the top-level installation directory HDF5, i.e. the library should be located in <code>${JULIA_HDF5_PATH}/lib</code>. Then run <code>import Pkg; Pkg.build(&quot;HDF5&quot;)</code>. In particular, this is required if you need parallel HDF5 support, which is not provided by the <code>HDF5_jll</code> binaries.</p><p>For example, to use HDF5 (<code>libhdf5-mpich-dev</code>) with MPI using system libraries on Ubuntu 20.04, you would run:</p><pre><code class="language-sh hljs">$ sudo apt install mpich libhdf5-mpich-dev
$ JULIA_HDF5_PATH=/usr/lib/x86_64-linux-gnu/hdf5/mpich/
$ JULIA_MPI_BINARY=system</code></pre><p>Then in Julia, run:</p><pre><code class="language-julia hljs">pkg&gt; build</code></pre><h2 id="Opening-and-closing-files"><a class="docs-heading-anchor" href="#Opening-and-closing-files">Opening and closing files</a><a id="Opening-and-closing-files-1"></a><a class="docs-heading-anchor-permalink" href="#Opening-and-closing-files" title="Permalink"></a></h2><p>&quot;Plain&quot; (i.e., with no extra formatting conventions) HDF5 files are created and/or opened with the <code>h5open</code> command:</p><pre><code class="language-julia hljs">fid = h5open(filename, mode)</code></pre><p>The mode can be any one of the following:</p><table><tr><th style="text-align: left">mode</th><th style="text-align: left">Meaning</th></tr><tr><td style="text-align: left">&quot;r&quot;</td><td style="text-align: left">read-only</td></tr><tr><td style="text-align: left">&quot;r+&quot;</td><td style="text-align: left">read-write, preserving any existing contents</td></tr><tr><td style="text-align: left">&quot;cw&quot;</td><td style="text-align: left">read-write, create file if not existing, preserve existing contents</td></tr><tr><td style="text-align: left">&quot;w&quot;</td><td style="text-align: left">read-write, destroying any existing contents (if any)</td></tr></table><p>For example</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using HDF5</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; fname = tempname(); # temporary file</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; fid = h5open(fname, &quot;w&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">üóÇÔ∏è HDF5.File: (read-write) /tmp/jl_ECe4X5</code></pre><p>This produces an object of type <code>HDF5File</code>, a subtype of the abstract type <code>DataFile</code>. This file will have no elements (groups, datasets, or attributes) that are not explicitly created by the user.</p><p>When you&#39;re finished with a file, you should close it:</p><pre><code class="language-julia hljs">close(fid)</code></pre><p>Closing a file also closes any other open objects (e.g., datasets, groups) in that file. In general, you need to close an HDF5 file to &quot;release&quot; it for use by other applications.</p><h2 id="Writing-a-group-or-dataset"><a class="docs-heading-anchor" href="#Writing-a-group-or-dataset">Writing a group or dataset</a><a id="Writing-a-group-or-dataset-1"></a><a class="docs-heading-anchor-permalink" href="#Writing-a-group-or-dataset" title="Permalink"></a></h2><p>Groups can be created as follows:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; create_group(fid, &quot;mygroup&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">üìÇ HDF5.Group: /mygroup (file: /tmp/jl_ECe4X5)</code></pre><p>We can write the <code>&quot;mydataset&quot;</code> by:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; fid[&quot;mydataset&quot;] = rand()</code><code class="nohighlight hljs ansi" style="display:block;">0.8609253883525574</code></pre><p>Or</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; create_dataset(fid, &quot;myvector&quot;, rand(10))</code><code class="nohighlight hljs ansi" style="display:block;">(HDF5.Dataset: /myvector (file: /tmp/jl_ECe4X5 xfer_mode: 0), HDF5.Datatype: H5T_IEEE_F64LE)</code></pre><p>Writing to a dataset to a group is as simple as:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; g = fid[&quot;mygroup&quot;]</code><code class="nohighlight hljs ansi" style="display:block;">üìÇ HDF5.Group: /mygroup (file: /tmp/jl_ECe4X5)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; g[&quot;mydataset&quot;] = &quot;Hello World!&quot;</code><code class="nohighlight hljs ansi" style="display:block;">&quot;Hello World!&quot;</code></pre><p>The <code>do</code> syntax is also supported, which will automatically take care of closing the file handle:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; h5open(&quot;example2.h5&quot;, &quot;w&quot;) do fid
           create_group(fid, &quot;mygroup&quot;)
       end</code><code class="nohighlight hljs ansi" style="display:block;">üìÇ HDF5.Group: (invalid)</code></pre><h2 id="Opening-and-closing-objects"><a class="docs-heading-anchor" href="#Opening-and-closing-objects">Opening and closing objects</a><a id="Opening-and-closing-objects-1"></a><a class="docs-heading-anchor-permalink" href="#Opening-and-closing-objects" title="Permalink"></a></h2><p>If you have a file object <code>fid</code>, and this has a group or dataset called <code>&quot;mygroup&quot;</code> at the top level of a file, you can open it in the following way:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; obj = fid[&quot;mygroup&quot;]</code><code class="nohighlight hljs ansi" style="display:block;">üìÇ HDF5.Group: /mygroup (file: /tmp/jl_ECe4X5)
‚îî‚îÄ üî¢ mydataset</code></pre><p>This does not read any data or attributes associated with the object, it&#39;s simply a handle for further manipulations. For example:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; g = fid[&quot;mygroup&quot;]</code><code class="nohighlight hljs ansi" style="display:block;">üìÇ HDF5.Group: /mygroup (file: /tmp/jl_ECe4X5)
‚îî‚îÄ üî¢ mydataset</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; dset = g[&quot;mydataset&quot;]</code><code class="nohighlight hljs ansi" style="display:block;">üî¢ HDF5.Dataset: /mygroup/mydataset (file: /tmp/jl_ECe4X5 xfer_mode: 0)</code></pre><p>or simply</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; dset = fid[&quot;mygroup/mydataset&quot;]</code><code class="nohighlight hljs ansi" style="display:block;">üî¢ HDF5.Dataset: /mygroup/mydataset (file: /tmp/jl_ECe4X5 xfer_mode: 0)</code></pre><p>When you&#39;re done with an object, you can close it using <code>close(obj)</code>. If you forget to do this, it will be closed for you anyway when the file is closed, or if <code>obj</code> goes out of scope and gets garbage collected.</p><h2 id="Reading-and-writing-data"><a class="docs-heading-anchor" href="#Reading-and-writing-data">Reading and writing data</a><a id="Reading-and-writing-data-1"></a><a class="docs-heading-anchor-permalink" href="#Reading-and-writing-data" title="Permalink"></a></h2><p>Suppose you have a group <code>g</code> which contains a dataset with path <code>&quot;mydataset&quot;</code>, and that you&#39;ve also opened this dataset as <code>dset = g[&quot;mydataset&quot;]</code>. You can read information in this dataset in any of the following ways:</p><pre><code class="language-julia hljs">A = read(dset)
A = read(g, &quot;mydataset&quot;)
Asub = dset[2:3, 1:3]</code></pre><p>The last syntax reads just a subset of the data array (assuming that <code>dset</code> is an array of sufficient size). libhdf5 has internal mechanisms for slicing arrays, and consequently if you need only a small piece of a large array, it can be faster to read just what you need rather than reading the entire array and discarding most of it.</p><p>Datasets can be created with either</p><pre><code class="language-julia hljs">g[&quot;mydataset&quot;] = rand(3,5)
write(g, &quot;mydataset&quot;, rand(3,5))</code></pre><p>One can use the high level interface <code>load</code> and <code>save</code> from <code>FileIO</code>, where an optional <code>OrderedDict</code> can be passed (<code>track_order</code> inferred). Note that using <code>track_order=true</code> or passing an <code>OrderedDict</code> is a promise that the read file has been created with the appropriate ordering flags.</p><pre><code class="language-julia hljs">julia&gt; using OrderedCollections, FileIO
julia&gt; save(&quot;track_order.h5&quot;, OrderedDict(&quot;z&quot;=&gt;1, &quot;a&quot;=&gt;2, &quot;g/f&quot;=&gt;3, &quot;g/b&quot;=&gt;4))
julia&gt; load(&quot;track_order.h5&quot;; dict=OrderedDict())
OrderedDict{Any, Any} with 4 entries:
  &quot;z&quot;   =&gt; 1
  &quot;a&quot;   =&gt; 2
  &quot;g/f&quot; =&gt; 3
  &quot;g/b&quot; =&gt; 4</code></pre><h2 id="Passing-parameters"><a class="docs-heading-anchor" href="#Passing-parameters">Passing parameters</a><a id="Passing-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Passing-parameters" title="Permalink"></a></h2><p>It is often required to pass parameters to specific routines, which are collected in so-called property lists in HDF5. There are different property lists for different tasks, e.g. for the access/creation of files, datasets, groups. In this high level framework multiple parameters can be simply applied by appending them at the end of function calls as keyword arguments.</p><pre><code class="language-julia hljs">g[&quot;A&quot;] = A  # basic
g[&quot;A&quot;, chunk=(5,5)] = A # add chunks

B = h5read(fn,&quot;mygroup/B&quot;, # two parameters
  fapl_mpio=(ccomm,cinfo), # if parameter requires multiple args use tuples
  dxpl_mpio=HDF5.H5FD_MPIO_COLLECTIVE )</code></pre><p>This will automatically create the correct property lists, add the properties, and apply the property list while reading/writing the data. The naming of the properties generally follows that of HDF5, i.e. the key <code>fapl_mpio</code> returns the HDF5 functions <code>h5pget/set_fapl_mpio</code> and their corresponding property list type <code>H5P_FILE_ACCESS</code>. The complete list if routines and their interfaces is available at the <a href="https://portal.hdfgroup.org/display/HDF5/Property+Lists">H5P: Property List Interface</a> documentation. Note that not all properties are available. When searching for a property check whether the corresponding <code>h5pget/set</code> functions are available.</p><h2 id="Chunking-and-compression"><a class="docs-heading-anchor" href="#Chunking-and-compression">Chunking and compression</a><a id="Chunking-and-compression-1"></a><a class="docs-heading-anchor-permalink" href="#Chunking-and-compression" title="Permalink"></a></h2><p>You can also optionally &quot;chunk&quot; and/or compress your data. For example,</p><pre><code class="language-julia hljs">A = rand(100,100)
g[&quot;A&quot;, chunk=(5,5)] = A</code></pre><p>stores the matrix <code>A</code> in 5-by-5 chunks. Chunking improves efficiency if you write or extract small segments or slices of an array, if these are not stored contiguously.</p><pre><code class="language-julia hljs">A = rand(100,100)
g1[&quot;A&quot;, chunk=(5,5), compress=3] = A
g2[&quot;A&quot;, chunk=(5,5), shuffle=(), deflate=3] = A
using H5Zblosc # load in Blosc
g3[&quot;A&quot;, chunk=(5,5), blosc=3] = A</code></pre><p>Standard compression in HDF5 (<code>&quot;compress&quot;</code>) corresponds to (<code>&quot;deflate&quot;</code>) and uses the <a href="http://en.wikipedia.org/wiki/DEFLATE">deflate/zlib</a> algorithm. The deflate algorithm is often more efficient if prefixed by a <code>&quot;shuffle&quot;</code> filter. Blosc is generally much faster than deflate ‚Äì however, reading Blosc-compressed HDF5 files require Blosc to be installed. This is the case for Julia, but often not for vanilla HDF5 distributions that may be used outside Julia. (In this case, the structure of the HDF5 file is still accessible, but compressed datasets cannot be read.) Compression requires chunking, and heuristic chunking is automatically used if you specify compression but don&#39;t specify chunking.</p><p>It is also possible to write to subsets of an on-disk HDF5 dataset. This is useful to incrementally save to very large datasets you don&#39;t want to keep in memory. For example,</p><pre><code class="language-julia hljs">dset = create_dataset(g, &quot;B&quot;, datatype(Float64), dataspace(1000,100,10), chunk=(100,100,1))
dset[:,1,1] = rand(1000)</code></pre><p>creates a Float64 dataset in the file or group <code>g</code>, with dimensions 1000x100x10, and then writes to just the first 1000 element slice. If you know the typical size of subset reasons you&#39;ll be reading/writing, it can be beneficial to set the chunk dimensions appropriately.</p><p>More <a href="#mid-level-routines">fine-grained control</a> is also available.</p><h2 id="Memory-mapping"><a class="docs-heading-anchor" href="#Memory-mapping">Memory mapping</a><a id="Memory-mapping-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-mapping" title="Permalink"></a></h2><p>If you will frequently be accessing individual elements or small regions of array datasets, it can be substantially more efficient to bypass HDF5 routines and use direct <a href="https://en.wikipedia.org/wiki/Memory-mapped_file">memory mapping</a>. This is possible only under particular conditions: when the dataset is an array of standard &quot;bits&quot; types (e.g., <code>Float64</code> or <code>Int32</code>) and no chunking/compression is being used. You can use the <code>ismmappable</code> function to test whether this is possible; for example,</p><pre><code class="language-julia hljs">dset = g[&quot;x&quot;]
if HDF5.ismmappable(dset)
    dset = HDF5.readmmap(dset)
end
val = dset[15]</code></pre><p>Note that <code>readmmap</code> returns an <code>Array</code> rather than an HDF5 object.</p><p><strong>Note</strong>: if you use <code>readmmap</code> on a dataset and subsequently close the file, the array data are still available‚Äì-and file continues to be in use‚Äì-until all of the arrays are garbage-collected. This is in contrast to standard HDF5 datasets, where closing the file prevents further access to any of the datasets, but the file is also detached and can safely be rewritten immediately.</p><p>Under the default <a href="https://portal.hdfgroup.org/display/HDF5/H5P_SET_ALLOC_TIME">allocation-time policy</a>, a newly added <code>ismmappable</code> dataset can only be memory mapped after it has been written to. The following fails:</p><pre><code class="language-julia hljs">vec_dset = create_dataset(g, &quot;v&quot;, datatype(Float64), dataspace(10_000,1))
HDF5.ismmappable(vec_dset)    # == true
vec = HDF5.readmmap(vec_dset) # throws ErrorException(&quot;Error mmapping array&quot;)</code></pre><p>because although the dataset description has been added, the space within the HDF5 file has not yet actually been allocated (so the file region cannot be memory mapped by the OS). The storage can be allocated by making at least one write:</p><pre><code class="language-julia hljs">vec_dset[1,1] = 0.0      # force allocation of /g/v within the file
vec = HDF5.readmmap(vec_dset) # and now the memory mapping can succeed</code></pre><p>Alternatively, the policy can be set so that the space is allocated immediately upon creation of the data set with the <code>alloc_time</code> keyword:</p><pre><code class="language-julia hljs">mtx_dset = create_dataset(g, &quot;M&quot;, datatype(Float64), dataspace(100, 1000),
                    alloc_time = HDF5.H5D_ALLOC_TIME_EARLY)
mtx = HDF5.readmmap(mtx_dset) # succeeds immediately</code></pre><h2 id="Supported-data-types"><a class="docs-heading-anchor" href="#Supported-data-types">Supported data types</a><a id="Supported-data-types-1"></a><a class="docs-heading-anchor-permalink" href="#Supported-data-types" title="Permalink"></a></h2><p><code>HDF5.jl</code> knows how to store values of the following types: signed and unsigned integers of 8, 16, 32, and 64 bits, <code>Float32</code>, <code>Float64</code>; <code>Complex</code> versions of these numeric types; <code>Array</code>s of these numeric types (including complex versions); <code>ASCIIString</code> and <code>UTF8String</code>; and <code>Array</code>s of these two string types. <code>Array</code>s of strings are supported using HDF5&#39;s variable-length-strings facility. By default <code>Complex</code> numbers are stored as compound types with <code>r</code> and <code>i</code> fields following the <code>h5py</code> convention. When reading data, compound types with matching field names will be loaded as the corresponding <code>Complex</code> Julia type. These field names are configurable with the <code>HDF5.set_complex_field_names(real::AbstractString, imag::AbstractString)</code> function and complex support can be completely enabled/disabled with <code>HDF5.enable/disable_complex_support()</code>.</p><p>For <code>Array</code>s, note that the array dimensionality is preserved, including 0-length dimensions:</p><pre><code class="language-julia hljs">fid[&quot;zero_vector&quot;] = zeros(0)
fid[&quot;zero_matrix&quot;] = zeros(0, 0)
size(fid[&quot;zero_vector&quot;]) # == (0,)
size(fid[&quot;zero_matrix&quot;]) # == (0, 0)</code></pre><p>An <em>exception</em> to this rule is Julia&#39;s 0-dimensional <code>Array</code>, which is stored as an HDF5 scalar because there is a value to be preserved:</p><pre><code class="language-julia hljs">fid[&quot;zero_dim_value&quot;] = fill(1.0œÄ)
read(fid[&quot;zero_dim_value&quot;]) # == 3.141592653589793, != [3.141592653589793]</code></pre><p>HDF5 also has the concept of a null array which contains a type but has neither size nor contents, which is represented by the type <code>HDF5.EmptyArray</code>:</p><pre><code class="language-julia hljs">fid[&quot;empty_array&quot;] = HDF5.EmptyArray{Float32}()
HDF5.isnull(fid[&quot;empty_array&quot;]) # == true
size(fid[&quot;empty_array&quot;]) # == ()
eltype(fid[&quot;empty_array&quot;]) # == Float32</code></pre><p>This module also supports HDF5&#39;s VLEN, OPAQUE, and REFERENCE types, which can be used to encode more complex types. In general, you need to specify how you want to combine these more advanced facilities to represent more complex data types. For many of the data types in Julia, the JLD module implements support. You can likewise define your own file format if, for example, you need to interact with some external program that has explicit formatting requirements.</p><h2 id="Creating-groups-and-attributes"><a class="docs-heading-anchor" href="#Creating-groups-and-attributes">Creating groups and attributes</a><a id="Creating-groups-and-attributes-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-groups-and-attributes" title="Permalink"></a></h2><p>Create a new group in the following way:</p><pre><code class="language-julia hljs">g = create_group(parent, name)</code></pre><p>The named group will be created as a child of the parent.</p><p>Attributes can be created using</p><pre><code class="language-julia hljs">attributes(parent)[name] = value</code></pre><p>where <code>attributes</code> simply indicates that the object referenced by <code>name</code> (a string) is an attribute, not another group or dataset. (Datasets cannot have child datasets, but groups can have either.) <code>value</code> must be a simple type: <code>BitsKind</code>s, strings, and arrays of either of these. The HDF5 standard recommends against storing large objects as attributes.</p><p>The value stored in an attribute can be retrieved like</p><pre><code class="language-julia hljs">read_attribute(parent, name)</code></pre><p>You can also access the value of an attribute by indexing, like so:</p><pre><code class="language-julia hljs">julia&gt; attr = attribute(parent)[name];
julia&gt; attr[]</code></pre><h2 id="Getting-information"><a class="docs-heading-anchor" href="#Getting-information">Getting information</a><a id="Getting-information-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-information" title="Permalink"></a></h2><pre><code class="language-julia hljs">HDF5.name(obj)</code></pre><p>will return the full HDF5 pathname of object <code>obj</code>.</p><pre><code class="language-julia hljs">keys(g)</code></pre><p>returns a string array containing all objects inside group <code>g</code>. These relative pathnames, not absolute pathnames.</p><p>You can iterate over the objects in a group, i.e.,</p><pre><code class="language-julia hljs">for obj in g
  data = read(obj)
  println(data)
end</code></pre><p>This gives you a straightforward way of recursively exploring an entire HDF5 file.</p><p>If you need to know whether group <code>g</code> has a dataset named <code>mydata</code>, you can test that with</p><pre><code class="language-julia hljs">if haskey(g, &quot;mydata&quot;)
   ...
end
tf = haskey(g, &quot;mydata&quot;)</code></pre><p>If instead you want to know whether <code>g</code> has an attribute named <code>myattribute</code>, do it this way:</p><pre><code class="language-julia hljs">tf = haskey(attributes(g), &quot;myattribute&quot;)</code></pre><p>If you have an HDF5 object, and you want to know where it fits in the hierarchy of the file, the following can be useful:</p><pre><code class="language-julia hljs">p = parent(obj)     # p is the parent object (usually a group)
fn = HDF5.filename(obj)  # fn is a string
g = HDF5.root(obj)       # g is the group &quot;/&quot;</code></pre><p>For array objects (datasets and attributes) the following methods work:</p><pre><code class="nohighlight hljs">dims = size(dset)
nd = ndims(dset)
len = length(dset)</code></pre><p>Objects can be created with properties, and you can query those properties in the following way:</p><pre><code class="nohighlight hljs">p = HDF5.get_create_properties(dset)
chunksz = HDF5.get_chunk(p)</code></pre><p>The simpler syntax <code>chunksz = HDF5.get_chunk(dset)</code> is also available.</p><p>Finally, sometimes you need to be able to conveniently test whether a file is an HDF5 file:</p><pre><code class="language-julia hljs">tf = HDF5.ishdf5(filename)</code></pre><h2 id="Mid-level-routines"><a class="docs-heading-anchor" href="#Mid-level-routines">Mid-level routines</a><a id="Mid-level-routines-1"></a><a class="docs-heading-anchor-permalink" href="#Mid-level-routines" title="Permalink"></a></h2><p>Sometimes you might want more fine-grained control, which can be achieved using a different set of routines. For example,</p><pre><code class="language-julia hljs">g = open_group(parent, name)
dset = open_dataset(parent, name[, apl])
attr = open_attribute(parent, name)
t = open_datatype(parent, name)</code></pre><p>These open the named group, dataset, attribute, and committed datatype, respectively. For datasets, <code>apl</code> stands for &quot;access parameter list&quot; and provides opportunities for more sophisticated control (see the <a href="https://www.hdfgroup.org/solutions/hdf5/">HDF5</a> documentation).</p><p>New objects can be created in the following ways:</p><pre><code class="language-julia hljs">g = create_group(parent, name[, lcpl, dcpl])
dset = create_dataset(parent, name, data[, lcpl, dcpl, dapl])
attr = create_attribute(parent, name, data)</code></pre><p>creates groups, datasets, and attributes without writing any data to them. You can then use <code>write(obj, data)</code> to store the data. The optional property lists allow even more fine-grained control. This syntax uses <code>data</code> to infer the object&#39;s &quot;HDF5.datatype&quot; and &quot;HDF5.dataspace&quot;; for the most explicit control, <code>data</code> can be replaced with <code>dtype, dspace</code>, where <code>dtype</code> is an <code>HDF5.Datatype</code> and <code>dspace</code> is an <code>HDF5.Dataspace</code>.</p><p>Analogously, to create committed data types, use</p><pre><code class="language-julia hljs">t = commit_datatype(parent, name, dtype[, lcpl, tcpl, tapl])</code></pre><p>You can create and write data in one step,</p><pre><code class="language-julia hljs">write_dataset(parent, name, data[, lcpl, dcpl, dapl])
write_attribute(parent, name, data)</code></pre><p>You can use extendible dimensions,</p><pre><code class="language-julia hljs">d = create_dataset(parent, name, dtype, (dims, max_dims), chunk=(chunk_dims))
HDF5.set_extent_dims(d, new_dims)</code></pre><p>where dims is a tuple of integers. For example</p><pre><code class="language-julia hljs">b = create_dataset(fid, &quot;b&quot;, Int, ((1000,),(-1,)), chunk=(100,)) #-1 is equivalent to typemax(hsize_t)
HDF5.set_extent_dims(b, (10000,))
b[1:10000] = collect(1:10000)</code></pre><p>when dimensions are reduced, the truncated data is lost. A maximum dimension of -1 is often referred to as unlimited dimensions, though it is limited by the maximum size of an unsigned integer.</p><p>Finally, it&#39;s possible to delete objects:</p><pre><code class="language-julia hljs">delete_object(parent, name)   # for groups, datasets, and datatypes
delete_attribute(parent, name)   # for attributes</code></pre><h2 id="Low-level-routines"><a class="docs-heading-anchor" href="#Low-level-routines">Low-level routines</a><a id="Low-level-routines-1"></a><a class="docs-heading-anchor-permalink" href="#Low-level-routines" title="Permalink"></a></h2><p>Many of the most commonly-used libhdf5 functions have been wrapped. These are not exported, so you need to preface them with <code>HDF5.function</code> to use them. The library follows a consistent convention: for example, libhdf5&#39;s <code>H5Adelete</code> is wrapped with a Julia function called <code>h5a_delete</code>. The arguments are exactly as specified in the <a href="https://www.hdfgroup.org/solutions/hdf5/">HDF5</a> reference manual.</p><p>HDF5 is a large library, and the low-level wrap is not complete. However, many of the most-commonly used functions are wrapped, and in general wrapping a new function takes only a single line of code. Users who need additional functionality are encourage to contribute it.</p><p>Note that Julia&#39;s HDF5 directly uses the &quot;2&quot; interfaces, e.g., <code>H5Dcreate2</code>, so you need to have version 1.8 of the HDF5 library or later.</p><h2 id="Parallel-HDF5"><a class="docs-heading-anchor" href="#Parallel-HDF5">Parallel HDF5</a><a id="Parallel-HDF5-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-HDF5" title="Permalink"></a></h2><p>It is possible to read and write <a href="https://portal.hdfgroup.org/display/HDF5/Parallel+HDF5">parallel HDF5</a> files using MPI. For this, the HDF5 binaries loaded by HDF5.jl must have been compiled with parallel support, and linked to the specific MPI implementation that will be used for parallel I/O.</p><p>Parallel-enabled HDF5 libraries are usually included in computing clusters and linked to the available MPI implementations. They are also available via the package manager of a number of Linux distributions.</p><p>Finally, note that the MPI.jl package is lazy-loaded by HDF5.jl using <a href="https://github.com/JuliaPackaging/Requires.jl">Requires</a>. In practice, this means that in Julia code, <code>MPI</code> must be imported <em>before</em> <code>HDF5</code> for parallel functionality to be available.</p><h3 id="Setting-up-Parallel-HDF5"><a class="docs-heading-anchor" href="#Setting-up-Parallel-HDF5">Setting-up Parallel HDF5</a><a id="Setting-up-Parallel-HDF5-1"></a><a class="docs-heading-anchor-permalink" href="#Setting-up-Parallel-HDF5" title="Permalink"></a></h3><p>The following step-by-step guide assumes one already has access to parallel-enabled HDF5 libraries linked to an existent MPI installation.</p><h4 id=".-Using-system-provided-MPI-libraries"><a class="docs-heading-anchor" href="#.-Using-system-provided-MPI-libraries">1. Using system-provided MPI libraries</a><a id=".-Using-system-provided-MPI-libraries-1"></a><a class="docs-heading-anchor-permalink" href="#.-Using-system-provided-MPI-libraries" title="Permalink"></a></h4><p>Set the environment variable <code>JULIA_MPI_BINARY=system</code> and then run <code>]build MPI</code> from Julia. For more control, one can also set the <code>JULIA_MPI_PATH</code> environment variable to the top-level installation directory of the MPI library. See the <a href="https://juliaparallel.github.io/MPI.jl/stable/configuration/#Using-a-system-provided-MPI-1">MPI.jl docs</a> for details.</p><h4 id=".-Using-parallel-HDF5-libraries"><a class="docs-heading-anchor" href="#.-Using-parallel-HDF5-libraries">2. Using parallel HDF5 libraries</a><a id=".-Using-parallel-HDF5-libraries-1"></a><a class="docs-heading-anchor-permalink" href="#.-Using-parallel-HDF5-libraries" title="Permalink"></a></h4><p>As detailed in <a href="#Using-custom-or-system-provided-HDF5-binaries">Using custom or system provided HDF5 binaries</a>, set the <code>JULIA_HDF5_PATH</code> environment variable to the path where the parallel HDF5 binaries are located. Then run <code>]build HDF5</code> from Julia.</p><h4 id=".-Loading-MPI-enabled-HDF5"><a class="docs-heading-anchor" href="#.-Loading-MPI-enabled-HDF5">3. Loading MPI-enabled HDF5</a><a id=".-Loading-MPI-enabled-HDF5-1"></a><a class="docs-heading-anchor-permalink" href="#.-Loading-MPI-enabled-HDF5" title="Permalink"></a></h4><p>In Julia code, MPI.jl must be loaded <em>before</em> HDF5.jl for MPI functionality to be available:</p><pre><code class="language-julia hljs">using MPI
using HDF5</code></pre><h3 id="Reading-and-writing-data-in-parallel"><a class="docs-heading-anchor" href="#Reading-and-writing-data-in-parallel">Reading and writing data in parallel</a><a id="Reading-and-writing-data-in-parallel-1"></a><a class="docs-heading-anchor-permalink" href="#Reading-and-writing-data-in-parallel" title="Permalink"></a></h3><p>A parallel HDF5 file may be opened by passing a <code>MPI.Comm</code> (and optionally a <code>MPI.Info</code>) object to <a href="#HDF5.h5open"><code>h5open</code></a>. For instance:</p><pre><code class="language-julia hljs">comm = MPI.COMM_WORLD
info = MPI.Info()
ff = h5open(filename, &quot;w&quot;, comm, info)</code></pre><p>MPI-distributed data is typically written by first creating a dataset describing the global dimensions of the data. The following example writes a <code>10 √ó Nproc</code> array distributed over <code>Nproc</code> MPI processes.</p><pre><code class="language-julia hljs">Nproc = MPI.Comm_size(comm)
myrank = MPI.Comm_rank(comm)
M = 10
A = fill(myrank, M)  # local data
dims = (M, Nproc)    # dimensions of global data

# Create dataset
dset = create_dataset(ff, &quot;/data&quot;, datatype(eltype(A)), dataspace(dims))

# Write local data
dset[:, myrank + 1] = A</code></pre><p>Note that all MPI processes must call <code>create_dataset</code> with the same arguments.</p><p>Sometimes, it may be more efficient to write data in chunks, so that each process writes to a separate chunk of the file. This is especially the case when data is uniformly distributed among MPI processes. In this example, this can be achieved by passing <code>chunk=(M, 1)</code> to <code>create_dataset</code>.</p><p>For better performance, it is sometimes preferable to perform <a href="https://portal.hdfgroup.org/display/HDF5/Introduction+to+Parallel+HDF5">collective I/O</a> when reading and writing datasets in parallel. This is achieved by passing <code>dxpl_mpio=HDF5.H5FD_MPIO_COLLECTIVE</code> to <code>create_dataset</code>. See also the <a href="https://portal.hdfgroup.org/display/HDF5/H5P_SET_DXPL_MPIO">HDF5 docs</a>.</p><p>A few more examples are available in <a href="https://github.com/JuliaIO/HDF5.jl/blob/master/test/mpio.jl"><code>test/mpio.jl</code></a>.</p><h2 id="Language-interoperability-with-row-and-column-major-order-arrays"><a class="docs-heading-anchor" href="#Language-interoperability-with-row-and-column-major-order-arrays">Language interoperability with row- and column-major order arrays</a><a id="Language-interoperability-with-row-and-column-major-order-arrays-1"></a><a class="docs-heading-anchor-permalink" href="#Language-interoperability-with-row-and-column-major-order-arrays" title="Permalink"></a></h2><p>There are two main methods for storing multidimensional arrays in linear storage <a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">row-major order and column-major order</a>. Julia, like Fortran and MATLAB, stores multidimensional arrays in column-major order, while other languages, including C and Python (NumPy), use row-major order. Therefore when reading an array in Julia from row-major order language the dimensions may be inverted.</p><p>To read a multidimensional array into the original shape from an HDF5 file written by Python (<code>numpy</code> and <code>h5py</code>) or C/C++/Objective-C, simply reverse the dimensions. For example, one may add the following line after reading the dataset <code>dset</code>:</p><pre><code class="language-julia hljs">dset = permutedims(dset, reverse(1:ndims(dset)))</code></pre><p>Note that some languages or libraries use both methods, so please check the datset&#39;s description for details. For example, NumPy arrays are row-major by default, but NumPy can use either row-major or column-major ordered arrays.</p><h2 id="Credits"><a class="docs-heading-anchor" href="#Credits">Credits</a><a id="Credits-1"></a><a class="docs-heading-anchor-permalink" href="#Credits" title="Permalink"></a></h2><ul><li><p>Konrad Hinsen initiated Julia&#39;s support for HDF5</p></li><li><p>Tim Holy and Simon Kornblith (primary authors)</p></li><li><p>Tom Short contributed code and ideas to the dictionary-like interface</p></li><li><p>Blake Johnson made several improvements, such as support for iterating over attributes</p></li><li><p>Isaiah Norton and Elliot Saba improved installation on Windows and OSX</p></li><li><p>Steve Johnson contributed the <code>do</code> syntax and Blosc compression</p></li><li><p>Mike Nolta and Jameson Nash contributed code or suggestions for improving the handling of HDF5&#39;s constants</p></li><li><p>Thanks also to the users who have reported bugs and tested fixes</p></li></ul><h1 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h1><p>Below we include a limited number of API references. Note not all of these are public interfaces, thus proceed with caution.</p><ul><li><a href="#HDF5.SHOW_TREE_ICONS"><code>HDF5.SHOW_TREE_ICONS</code></a></li><li><a href="#HDF5.SHOW_TREE_MAX_CHILDREN"><code>HDF5.SHOW_TREE_MAX_CHILDREN</code></a></li><li><a href="#HDF5.SHOW_TREE_MAX_DEPTH"><code>HDF5.SHOW_TREE_MAX_DEPTH</code></a></li><li><a href="#Base.isopen-Tuple{HDF5.File}"><code>Base.isopen</code></a></li><li><a href="#HDF5.create_dataset-Tuple{Union{HDF5.File, HDF5.Group}, AbstractString, HDF5.Datatype, HDF5.Dataspace}"><code>HDF5.create_dataset</code></a></li><li><a href="#HDF5.create_external-Tuple{Union{HDF5.File, HDF5.Group}, Any, Any, Any}"><code>HDF5.create_external</code></a></li><li><a href="#HDF5.create_external_dataset"><code>HDF5.create_external_dataset</code></a></li><li><a href="#HDF5.do_read_chunk-Tuple{HDF5.Dataset, Any}"><code>HDF5.do_read_chunk</code></a></li><li><a href="#HDF5.do_read_chunk-Tuple{HDF5.Dataset, Integer}"><code>HDF5.do_read_chunk</code></a></li><li><a href="#HDF5.do_write_chunk"><code>HDF5.do_write_chunk</code></a></li><li><a href="#HDF5.do_write_chunk"><code>HDF5.do_write_chunk</code></a></li><li><a href="#HDF5.get_chunk_index-Tuple{Any, Any}"><code>HDF5.get_chunk_index</code></a></li><li><a href="#HDF5.get_chunk_length-Tuple{Any}"><code>HDF5.get_chunk_length</code></a></li><li><a href="#HDF5.get_chunk_offset-Tuple{Any, Any}"><code>HDF5.get_chunk_offset</code></a></li><li><a href="#HDF5.get_datasets-Tuple{HDF5.File}"><code>HDF5.get_datasets</code></a></li><li><a href="#HDF5.get_extent_dims-Tuple{Union{HDF5.Attribute, HDF5.Dataset, HDF5.Dataspace}}"><code>HDF5.get_extent_dims</code></a></li><li><a href="#HDF5.get_num_chunks-Tuple{Any}"><code>HDF5.get_num_chunks</code></a></li><li><a href="#HDF5.get_num_chunks_per_dim-Tuple{Any}"><code>HDF5.get_num_chunks_per_dim</code></a></li><li><a href="#HDF5.h5open"><code>HDF5.h5open</code></a></li><li><a href="#HDF5.h5open-Tuple{Function, Vararg{Any}}"><code>HDF5.h5open</code></a></li><li><a href="#HDF5.has_parallel-Tuple{}"><code>HDF5.has_parallel</code></a></li><li><a href="#HDF5.ishdf5-Tuple{AbstractString}"><code>HDF5.ishdf5</code></a></li><li><a href="#HDF5.isnull-Tuple{Union{HDF5.Attribute, HDF5.Dataset, HDF5.Dataspace}}"><code>HDF5.isnull</code></a></li><li><a href="#HDF5.read_attribute-Tuple{Union{HDF5.Dataset, HDF5.Datatype, HDF5.File, HDF5.Group}, AbstractString}"><code>HDF5.read_attribute</code></a></li><li><a href="#HDF5.read_chunk"><code>HDF5.read_chunk</code></a></li><li><a href="#HDF5.read_chunk"><code>HDF5.read_chunk</code></a></li><li><a href="#HDF5.set_extent_dims-Tuple{HDF5.Dataset, Tuple{Vararg{Int64, N}} where N}"><code>HDF5.set_extent_dims</code></a></li><li><a href="#HDF5.set_extent_dims"><code>HDF5.set_extent_dims</code></a></li><li><a href="#HDF5.setproperties!-Tuple{Vararg{HDF5.Properties}}"><code>HDF5.setproperties!</code></a></li><li><a href="#HDF5.start_swmr_write-Tuple{HDF5.File}"><code>HDF5.start_swmr_write</code></a></li><li><a href="#HDF5.write_chunk-Tuple{Any, Any, AbstractArray}"><code>HDF5.write_chunk</code></a></li><li><a href="#HDF5.write_chunk-Tuple{Any, Integer, AbstractArray}"><code>HDF5.write_chunk</code></a></li><li><a href="#HDF5.@bool_property-Tuple{Any}"><code>HDF5.@bool_property</code></a></li><li><a href="#HDF5.@enum_property-Tuple{Any, Vararg{Any}}"><code>HDF5.@enum_property</code></a></li><li><a href="#HDF5.@propertyclass-Tuple{Any, Any}"><code>HDF5.@propertyclass</code></a></li><li><a href="#HDF5.@tuple_property-Tuple{Any}"><code>HDF5.@tuple_property</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="HDF5.SHOW_TREE_ICONS" href="#HDF5.SHOW_TREE_ICONS"><code>HDF5.SHOW_TREE_ICONS</code></a> ‚Äî <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">SHOW_TREE_ICONS = Ref{Bool}(true)</code></pre><p>Configurable option to control whether emoji icons (<code>true</code>) or a plain-text annotation (<code>false</code>) is used to indicate the object type by <code>show_tree</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/show.jl#L129-L134">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.SHOW_TREE_MAX_CHILDREN" href="#HDF5.SHOW_TREE_MAX_CHILDREN"><code>HDF5.SHOW_TREE_MAX_CHILDREN</code></a> ‚Äî <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">SHOW_TREE_MAX_CHILDREN = Ref{Int}(50)</code></pre><p>Maximum number of children to show at each node.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/show.jl#L144-L148">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.SHOW_TREE_MAX_DEPTH" href="#HDF5.SHOW_TREE_MAX_DEPTH"><code>HDF5.SHOW_TREE_MAX_DEPTH</code></a> ‚Äî <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">SHOW_TREE_MAX_DEPTH = Ref{Int}(5)</code></pre><p>Maximum recursive depth to descend during printing.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/show.jl#L137-L141">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.isopen-Tuple{HDF5.File}" href="#Base.isopen-Tuple{HDF5.File}"><code>Base.isopen</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">isopen(obj::HDF5.File)</code></pre><p>Returns <code>true</code> if <code>obj</code> has not been closed, <code>false</code> if it has been closed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L409-L413">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.create_dataset-Tuple{Union{HDF5.File, HDF5.Group}, AbstractString, HDF5.Datatype, HDF5.Dataspace}" href="#HDF5.create_dataset-Tuple{Union{HDF5.File, HDF5.Group}, AbstractString, HDF5.Datatype, HDF5.Dataspace}"><code>HDF5.create_dataset</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">create_dataset(parent, path, datatype, dataspace; properties...)</code></pre><p><strong>Arguments</strong></p><ul><li><code>parent</code> - <code>File</code> or <code>Group</code></li><li><code>path</code> - String describing the path of the dataset within the HDF5 file</li><li><code>datatype</code> - <code>Datatype</code> or <code>Type</code> or the dataset</li><li><code>dataspace</code> - <code>Dataspace</code> or <code>Dims</code> of the dataset</li><li><code>properties</code> - keyword name-value pairs set properties of the dataset</li></ul><p><strong>Keywords</strong></p><p>There are many keyword properties that can be set. Below are a few select keywords.</p><ul><li><code>chunk</code> - <code>Dims</code> describing the size of a chunk. Needed to apply filters.</li><li><code>filters</code> - <code>AbstractVector{&lt;: Filters.Filter}</code> describing the order of the filters to apply to the data. See <a href="../filters/#HDF5.Filters"><code>Filters</code></a></li><li><code>external</code> - <code>Tuple{AbstractString, Intger, Integer}</code> <code>(filepath, offset, filesize)</code> External dataset file location, data offset, and file size. See <a href="../api_bindings/#HDF5.API.h5p_set_external"><code>API.h5p_set_external</code></a>.</li></ul><p>See also</p><ul><li><a href="../api_bindings/#H5P"><code>H5P</code></a></li><li><a href="../properties/#HDF5.DatasetCreateProperties"><code>DatasetCreateProperties</code></a></li><li><a href="../properties/#HDF5.DatasetTransferProperties"><code>DatasetTransferProperties</code></a></li><li><a href="../properties/#HDF5.DatasetAccessProperties"><code>DatasetAccessProperties</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L565-L587">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.create_external-Tuple{Union{HDF5.File, HDF5.Group}, Any, Any, Any}" href="#HDF5.create_external-Tuple{Union{HDF5.File, HDF5.Group}, Any, Any, Any}"><code>HDF5.create_external</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">create_external(source::Union{HDF5.File, HDF5.Group}, source_relpath, target_filename, target_path;
                lcpl_id=HDF5.API.H5P_DEFAULT, lapl_id=HDF5.H5P.DEFAULT)</code></pre><p>Create an external link such that <code>source[source_relpath]</code> points to <code>target_path</code> within the file with path <code>target_filename</code>; Calls <code>[H5Lcreate_external](https://www.hdfgroup.org/HDF5/doc/RM/RM_H5L.html#Link-CreateExternal)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L1630-L1636">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.create_external_dataset" href="#HDF5.create_external_dataset"><code>HDF5.create_external_dataset</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">create_external_dataset(parent, name, filepath, dtype, dspace, offset = 0)</code></pre><p>Create a external dataset with data in an external file.</p><ul><li><code>parent</code> - File or Group</li><li><code>name</code> - Name of the Dataset</li><li><code>filepath</code> - File path to where the data is tored</li><li><code>dtype</code> - Datatype, Type, or value where <code>datatype</code> is applicable</li><li><code>offset</code> - Offset, in bytes, from the beginning of the file to the location in the file where the data starts.</li></ul><p>Use <code>API.h5p_set_external</code> to link to multiple segments.</p><p>See also <a href="api_bindings/#HDF5.API.h5p_set_external"><code>API.h5p_set_external</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L1368-L1381">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.do_read_chunk-Tuple{HDF5.Dataset, Any}" href="#HDF5.do_read_chunk-Tuple{HDF5.Dataset, Any}"><code>HDF5.do_read_chunk</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">do_read_chunk(dataset::Dataset, offset)</code></pre><p>Read a raw chunk at a given offset. <code>offset</code> is a 1-based list of rank <code>ndims(dataset)</code> and must fall on a chunk boundary.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L1416-L1421">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.do_read_chunk-Tuple{HDF5.Dataset, Integer}" href="#HDF5.do_read_chunk-Tuple{HDF5.Dataset, Integer}"><code>HDF5.do_read_chunk</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">do_read_chunk(dataset::Dataset, index::Integer)</code></pre><p>Read a raw chunk at a given index. <code>index</code> is 1-based and consecutive up to the number of chunks.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L1430-L1435">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.do_write_chunk" href="#HDF5.do_write_chunk"><code>HDF5.do_write_chunk</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">do_write_chunk(dataset::Dataset, index, chunk_bytes::AbstractArray, filter_mask=0)</code></pre><p>Write a raw chunk at a given linear index. <code>chunk_bytes</code> is an AbstractArray that can be converted to a pointer, Ptr{Cvoid}. <code>index</code> is 1-based and consecutive up to the number of chunks.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L1403-L1409">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.do_write_chunk" href="#HDF5.do_write_chunk"><code>HDF5.do_write_chunk</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">do_write_chunk(dataset::Dataset, offset, chunk_bytes::AbstractArray, filter_mask=0)</code></pre><p>Write a raw chunk at a given offset. <code>chunk_bytes</code> is an AbstractArray that can be converted to a pointer, Ptr{Cvoid}. <code>offset</code> is a 1-based list of rank <code>ndims(dataset)</code> and must fall on a chunk boundary.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L1390-L1396">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.get_chunk_index-Tuple{Any, Any}" href="#HDF5.get_chunk_index-Tuple{Any, Any}"><code>HDF5.get_chunk_index</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">HDF5.get_chunk_index(dataset_id, offset)</code></pre><p>Get 0-based index of chunk from 0-based <code>offset</code> returned in Julia&#39;s column-major order. For a 1-based API, see <code>HDF5.ChunkStorage</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L62-L67">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.get_chunk_length-Tuple{Any}" href="#HDF5.get_chunk_length-Tuple{Any}"><code>HDF5.get_chunk_length</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">HDF5.get_chunk_length(dataset_id)</code></pre><p>Retrieves the chunk size in bytes. Equivalent to <code>API.h5d_get_chunk_info(dataset_id, index)[:size]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L99-L103">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.get_chunk_offset-Tuple{Any, Any}" href="#HDF5.get_chunk_offset-Tuple{Any, Any}"><code>HDF5.get_chunk_offset</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">HDF5.get_chunk_offset(dataset_id, index)</code></pre><p>Get 0-based offset of chunk from 0-based <code>index</code>. The offsets are returned in Julia&#39;s column-major order rather than hdf5 row-major order. For a 1-based API, see <code>HDF5.ChunkStorage</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L48-L53">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.get_datasets-Tuple{HDF5.File}" href="#HDF5.get_datasets-Tuple{HDF5.File}"><code>HDF5.get_datasets</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_datasets(file::HDF5.File) -&gt; datasets::Vector{HDF5.Dataset}</code></pre><p>Get all the datasets in an hdf5 file without loading the data.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L1606-L1610">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.get_extent_dims-Tuple{Union{HDF5.Attribute, HDF5.Dataset, HDF5.Dataspace}}" href="#HDF5.get_extent_dims-Tuple{Union{HDF5.Attribute, HDF5.Dataset, HDF5.Dataspace}}"><code>HDF5.get_extent_dims</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">HDF5.get_extent_dims(obj::Union{HDF5.Dataspace, HDF5.Dataset, HDF5.Attribute}) -&gt; dims, maxdims</code></pre><p>Get the array dimensions from a dataspace, dataset, or attribute and return a tuple of <code>dims</code> and <code>maxdims</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L32-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.get_num_chunks-Tuple{Any}" href="#HDF5.get_num_chunks-Tuple{Any}"><code>HDF5.get_num_chunks</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">HDF5.get_num_chunks(dataset_id)</code></pre><p>Returns the number of chunks in a dataset. Equivalent to <code>API.h5d_get_num_chunks(dataset_id, HDF5.H5S_ALL)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L86-L90">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.get_num_chunks_per_dim-Tuple{Any}" href="#HDF5.get_num_chunks_per_dim-Tuple{Any}"><code>HDF5.get_num_chunks_per_dim</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">HDF5.get_num_chunks_per_dim(dataset_id)</code></pre><p>Get the number of chunks in each dimension in Julia&#39;s column-major order.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L75-L79">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.h5open" href="#HDF5.h5open"><code>HDF5.h5open</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">h5open(filename::AbstractString, mode::AbstractString=&quot;r&quot;; swmr=false, pv...)</code></pre><p>Open or create an HDF5 file where <code>mode</code> is one of:</p><ul><li>&quot;r&quot;  read only</li><li>&quot;r+&quot; read and write</li><li>&quot;cw&quot; read and write, create file if not existing, do not truncate</li><li>&quot;w&quot;  read and write, create a new file (destroys any existing contents)</li></ul><p>Pass <code>swmr=true</code> to enable (Single Writer Multiple Reader) SWMR write access for &quot;w&quot; and &quot;r+&quot;, or SWMR read access for &quot;r&quot;.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L222-L233">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.h5open-Tuple{Function, Vararg{Any}}" href="#HDF5.h5open-Tuple{Function, Vararg{Any}}"><code>HDF5.h5open</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">function h5open(f::Function, args...; swmr=false, pv...)</code></pre><p>Apply the function f to the result of <code>h5open(args...; kwargs...)</code> and close the resulting <code>HDF5.File</code> upon completion. For example with a <code>do</code> block:</p><pre><code class="nohighlight hljs">h5open(&quot;foo.h5&quot;,&quot;w&quot;) do h5
    h5[&quot;foo&quot;]=[1,2,3]
end</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L276-L286">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.has_parallel-Tuple{}" href="#HDF5.has_parallel-Tuple{}"><code>HDF5.has_parallel</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">has_parallel()</code></pre><p>Returns <code>true</code> if the HDF5 libraries were compiled with parallel support, and if parallel functionality was loaded into HDF5.jl.</p><p>For the second condition to be true, MPI.jl must be imported before HDF5.jl.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L1644-L1651">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.ishdf5-Tuple{AbstractString}" href="#HDF5.ishdf5-Tuple{AbstractString}"><code>HDF5.ishdf5</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ishdf5(name::AbstractString)</code></pre><p>Returns <code>true</code> if the file specified by <code>name</code> is in the HDF5 format, and <code>false</code> otherwise.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L461-L465">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.isnull-Tuple{Union{HDF5.Attribute, HDF5.Dataset, HDF5.Dataspace}}" href="#HDF5.isnull-Tuple{Union{HDF5.Attribute, HDF5.Dataset, HDF5.Dataspace}}"><code>HDF5.isnull</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">isnull(dspace::Union{HDF5.Dataspace, HDF5.Dataset, HDF5.Attribute})</code></pre><p>Determines whether the given object has no size (consistent with the <code>API.H5S_NULL</code> dataspace).</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; HDF5.isnull(dataspace(HDF5.EmptyArray{Float64}()))
true

julia&gt; HDF5.isnull(dataspace((0,)))
false</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L813-L826">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.read_attribute-Tuple{Union{HDF5.Dataset, HDF5.Datatype, HDF5.File, HDF5.Group}, AbstractString}" href="#HDF5.read_attribute-Tuple{Union{HDF5.Dataset, HDF5.Datatype, HDF5.File, HDF5.Group}, AbstractString}"><code>HDF5.read_attribute</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">read_attribute(parent::Union{File,Group,Dataset,Datatype}, name::AbstractString)</code></pre><p>Read the value of the named attribute on the parent object.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; HDF5.read_attribute(g, &quot;time&quot;)
2.45</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L867-L877">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.read_chunk" href="#HDF5.read_chunk"><code>HDF5.read_chunk</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">HDF5.read_chunk(dataset_id, index::Integer, [buf]; dxpl_id = HDF5.API.H5P_DEFAULT, filters = Ref{UInt32}())</code></pre><p>Helper method to read chunks via 0-based integer <code>index</code>.</p><p>Argument <code>buf</code> is optional and defaults to a <code>Vector{UInt8}</code> of length determined by <code>HDF5.h5d_get_chunk_info</code>. Argument <code>dxpl_id</code> can be supplied a keyword and defaults to <code>HDF5.API.H5P_DEFAULT</code>. Argument <code>filters</code> can be retrieved by supplying a <code>Ref{UInt32}</code> value via a keyword argument.</p><p>This method returns <code>Vector{UInt8}</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L136-L146">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.read_chunk" href="#HDF5.read_chunk"><code>HDF5.read_chunk</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">HDF5.read_chunk(dataset_id, offset, [buf]; dxpl_id = HDF5.API.H5P_DEFAULT, filters = Ref{UInt32}())</code></pre><p>Helper method to read chunks via 0-based offsets in a <code>Tuple</code>.</p><p>Argument <code>buf</code> is optional and defaults to a <code>Vector{UInt8}</code> of length determined by <code>HDF5.get_chunk_length</code>. Argument <code>dxpl_id</code> can be supplied a keyword and defaults to <code>HDF5.API.H5P_DEFAULT</code>. Argument <code>filters</code> can be retrieved by supplying a <code>Ref{UInt32}</code> value via a keyword argument.</p><p>This method returns <code>Vector{UInt8}</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L116-L126">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.set_extent_dims" href="#HDF5.set_extent_dims"><code>HDF5.set_extent_dims</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">HDF5.set_extent_dims(dspace::HDF5.Dataspace, new_dims::Dims, max_dims::Union{Dims,Nothing} = nothing)</code></pre><p>Change the dimensions of a dataspace <code>dspace</code> to <code>new_dims</code>, optionally with the maximum possible dimensions <code>max_dims</code> different from the active size <code>new_dims</code>. If not given, <code>max_dims</code> is set equal to <code>new_dims</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L16-L22">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.set_extent_dims-Tuple{HDF5.Dataset, Tuple{Vararg{Int64, N}} where N}" href="#HDF5.set_extent_dims-Tuple{HDF5.Dataset, Tuple{Vararg{Int64, N}} where N}"><code>HDF5.set_extent_dims</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">HDF5.set_extent_dims(dset::HDF5.Dataset, new_dims::Dims)</code></pre><p>Change the current dimensions of a dataset to <code>new_dims</code>, limited by <code>max_dims = get_extent_dims(dset)[2]</code>. Reduction is possible and leads to loss of truncated data.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L5-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.setproperties!-Tuple{Vararg{HDF5.Properties}}" href="#HDF5.setproperties!-Tuple{Vararg{HDF5.Properties}}"><code>HDF5.setproperties!</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">setproperties!(props::Properties...; kwargs...)</code></pre><p>For each <code>(key, value)</code> pair in <code>kwargs</code>, set the corresponding properties in each <code>Properties</code> object in <code>props</code>. Returns a <code>Dict</code> of any pairs which didn&#39;t match properties in <code>props</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/properties.jl#L118-L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.start_swmr_write-Tuple{HDF5.File}" href="#HDF5.start_swmr_write-Tuple{HDF5.File}"><code>HDF5.start_swmr_write</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">start_swmr_write(h5::HDF5.File)</code></pre><p>Start Single Reader Multiple Writer (SWMR) writing mode. See <a href="https://portal.hdfgroup.org/display/HDF5/Single+Writer+Multiple+Reader++-+SWMR">SWMR documentation</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/HDF5.jl#L843-L848">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.write_chunk-Tuple{Any, Any, AbstractArray}" href="#HDF5.write_chunk-Tuple{Any, Any, AbstractArray}"><code>HDF5.write_chunk</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">HDF5.write_chunk(dataset_id, offset, buf::AbstractArray; dxpl_id = HDF5.API.H5P_DEFAULT, filter_mask = 0)</code></pre><p>Helper method to write chunks via 0-based offsets <code>offset</code> as a <code>Tuple</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L156-L160">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.write_chunk-Tuple{Any, Integer, AbstractArray}" href="#HDF5.write_chunk-Tuple{Any, Integer, AbstractArray}"><code>HDF5.write_chunk</code></a> ‚Äî <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">HDF5.write_chunk(dataset_id, index::Integer, buf::AbstractArray; dxpl_id = API.H5P_DEFAULT, filter_mask = 0)</code></pre><p>Helper method to write chunks via 0-based integer <code>index</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/api_midlevel.jl#L172-L176">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.@bool_property-Tuple{Any}" href="#HDF5.@bool_property-Tuple{Any}"><code>HDF5.@bool_property</code></a> ‚Äî <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@bool_property(name)</code></pre><p>Wrap property getter/setter API functions that use <code>0</code>/<code>1</code> to use <code>Bool</code> values</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/properties.jl#L200-L204">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.@enum_property-Tuple{Any, Vararg{Any}}" href="#HDF5.@enum_property-Tuple{Any, Vararg{Any}}"><code>HDF5.@enum_property</code></a> ‚Äî <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@enum_property(name, sym1 =&gt; enumvalue1, sym2 =&gt; enumvalue2, ...)</code></pre><p>Wrap property getter/setter API functions that use enum values to use symbol instead.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/properties.jl#L162-L166">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.@propertyclass-Tuple{Any, Any}" href="#HDF5.@propertyclass-Tuple{Any, Any}"><code>HDF5.@propertyclass</code></a> ‚Äî <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@propertyclass P classid</code></pre><p>Define a new subtype of <code>P &lt;: Properties</code> corresponding to a HDF5 property list with class identifier <code>classid</code>.</p><p>Once defined, the following interfaces can be defined:</p><pre><code class="nohighlight hljs">superclass(::Type{P})</code></pre><p>This should return the type from which <code>P</code> inherits. If not defined, it will inherit from <code>GenericProperties</code>.</p><pre><code class="nohighlight hljs">class_propertynames(::Type{P})</code></pre><p>This should return a <code>Tuple</code> of <code>Symbol</code>s, being the names of the properties associated with <code>P</code>.</p><pre><code class="nohighlight hljs">class_getproperty(::Type{P}, p::Properties, name::Symbol)</code></pre><p>If <code>name</code> is an associated property of type <code>P</code>, this should return the value of the propery, otherwise call <code>class_getproperty(superclass(P), p, name)</code>.</p><pre><code class="nohighlight hljs">class_setproperty!(::Type{P}, p::Properties, name::Symbol, val)</code></pre><p>If <code>name</code> is an associated property of type <code>P</code>, this should set the value of the propery, otherwise call <code>class_setproperty!(superclass(P), p, name, val)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/properties.jl#L62-L89">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="HDF5.@tuple_property-Tuple{Any}" href="#HDF5.@tuple_property-Tuple{Any}"><code>HDF5.@tuple_property</code></a> ‚Äî <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@tuple_property(name)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaIO/HDF5.jl/blob/785f1e237a3e83a5846cd91f878a9d1cf42c6f8c/src/properties.jl#L144-L146">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="dataset/">Dataset ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.12 on <span class="colophon-date" title="Sunday 13 March 2022 21:31">Sunday 13 March 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
