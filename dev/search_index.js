var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = HDF5","category":"page"},{"location":"#HDF5.jl","page":"Home","title":"HDF5.jl","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"HDF5 stands for Hierarchical Data Format v5 and is closely modeled on file systems. In HDF5, a \"group\" is analogous to a directory, a \"dataset\" is like a file. HDF5 also uses \"attributes\" to associate metadata with a particular group or dataset. HDF5 uses ASCII names for these different objects, and objects can be accessed by UNIX-like pathnames, e.g., \"/sample1/tempsensor/firsttrial\" for a top-level group \"sample1\", a subgroup \"tempsensor\", and a dataset \"firsttrial\".","category":"page"},{"location":"","page":"Home","title":"Home","text":"For simple types (scalars, strings, and arrays), HDF5 provides sufficient metadata to know how each item is to be interpreted. For example, HDF5 encodes that a given block of bytes is to be interpreted as an array of Int64, and represents them in a way that is compatible across different computing architectures.","category":"page"},{"location":"","page":"Home","title":"Home","text":"However, to preserve Julia objects, one generally needs additional type information to be supplied, which is easy to provide using attributes. This is handled for you automatically in the JLD and MatIO modules for *.jld and *.mat files. These specific formats (conventions) provide \"extra\" functionality, but they are still both regular HDF5 files and are therefore compatible with any HDF5 reader or writer.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Language wrappers for HDF5 are often described as either \"low level\" or \"high level.\" This package contains both flavors: at the low level, it directly wraps HDF5's functions, thus copying their API and making them available from within Julia. At the high level, it provides a set of functions built on the low-level wrap which may make the usage of this library more convenient.","category":"page"},{"location":"#Opening-and-closing-files","page":"Home","title":"Opening and closing files","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"\"Plain\" (i.e., with no extra formatting conventions) HDF5 files are created and/or opened with the h5open command:","category":"page"},{"location":"","page":"Home","title":"Home","text":"fid = h5open(filename, mode)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The mode can be any one of the following:","category":"page"},{"location":"","page":"Home","title":"Home","text":"mode Meaning\n\"r\" read-only\n\"r+\" read-write, preserving any existing contents\n\"cw\" read-write, create file if not existing, preserve existing contents\n\"w\" read-write, destroying any existing contents (if any)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This produces an object of type HDF5File, a subtype of the abstract type DataFile. This file will have no elements (groups, datasets, or attributes) that are not explicitly created by the user.","category":"page"},{"location":"","page":"Home","title":"Home","text":"When you're finished with a file, you should close it:","category":"page"},{"location":"","page":"Home","title":"Home","text":"close(fid)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Closing a file also closes any other open objects (e.g., datasets, groups) in that file. In general, you need to close an HDF5 file to \"release\" it for use by other applications.","category":"page"},{"location":"#Opening-and-closing-objects","page":"Home","title":"Opening and closing objects","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you have a file object fid, and this has a group or dataset called \"myobject\" at the top level of a file, you can open it in the following way:","category":"page"},{"location":"","page":"Home","title":"Home","text":"obj = fid[\"myobject\"]","category":"page"},{"location":"","page":"Home","title":"Home","text":"This does not read any data or attributes associated with the object, it's simply a handle for further manipulations. For example:","category":"page"},{"location":"","page":"Home","title":"Home","text":"g = fid[\"mygroup\"]\ndset = g[\"mydataset\"]","category":"page"},{"location":"","page":"Home","title":"Home","text":"or simply","category":"page"},{"location":"","page":"Home","title":"Home","text":"dset = fid[\"mygroup/mydataset\"]","category":"page"},{"location":"","page":"Home","title":"Home","text":"When you're done with an object, you can close it using close(obj). If you forget to do this, it will be closed for you anyway when the file is closed, or if obj goes out of scope and gets garbage collected.","category":"page"},{"location":"#Reading-and-writing-data","page":"Home","title":"Reading and writing data","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Suppose you have a group g which contains a dataset with path \"mydataset\", and that you've also opened this dataset as dset = g[\"mydataset\"]. You can read information in this dataset in any of the following ways:","category":"page"},{"location":"","page":"Home","title":"Home","text":"A = read(dset)\nA = read(g, \"mydataset\")\nAsub = dset[2:3, 1:3]","category":"page"},{"location":"","page":"Home","title":"Home","text":"The last syntax reads just a subset of the data array (assuming that dset is an array of sufficient size). libhdf5 has internal mechanisms for slicing arrays, and consequently if you need only a small piece of a large array, it can be faster to read just what you need rather than reading the entire array and discarding most of it.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Datasets can be created with either","category":"page"},{"location":"","page":"Home","title":"Home","text":"g[\"mydataset\"] = rand(3,5)\nwrite(g, \"mydataset\", rand(3,5))","category":"page"},{"location":"#Passing-parameters","page":"Home","title":"Passing parameters","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"It is often required to pass parameters to specific routines, which are collected in so-called property lists in HDF5. There are different property lists for different tasks, e.g. for the access/creation of files, datasets, groups. In this high level framework multiple parameters can be simply applied by appending them at the end of function calls as keyword arguments.","category":"page"},{"location":"","page":"Home","title":"Home","text":"g[\"A\"] = A  # basic\ng[\"A\", chunk=(5,5)] = A # add chunks\n\nB=h5read(fn,\"mygroup/B\", # two parameters\n  fapl_mpio=(ccomm,cinfo), # if parameter requires multiple args use tuples\n  dxpl_mpio=HDF5.H5FD_MPIO_COLLECTIVE )","category":"page"},{"location":"","page":"Home","title":"Home","text":"This will automatically create the correct property lists, add the properties, and apply the property list while reading/writing the data. The naming of the properties generally follows that of HDF5, i.e. the key fapl_mpio returns the HDF5 functions h5pget/set_fapl_mpio and their corresponding property list type H5P_FILE_ACCESS. The complete list if routines and their interfaces is available at the H5P: Property List Interface documentation. Note that not all properties are available. When searching for a property check whether the corresponding h5pget/set functions are available.","category":"page"},{"location":"#Chunking-and-compression","page":"Home","title":"Chunking and compression","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can also optionally \"chunk\" and/or compress your data. For example,","category":"page"},{"location":"","page":"Home","title":"Home","text":"A = rand(100,100)\ng[\"A\", chunk=(5,5)] = A","category":"page"},{"location":"","page":"Home","title":"Home","text":"stores the matrix A in 5-by-5 chunks. Chunking improves efficiency if you write or extract small segments or slices of an array, if these are not stored contiguously.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A = rand(100,100)\ng1[\"A\", chunk=(5,5), compress=3] = A\ng2[\"A\", chunk=(5,5), shuffle=(), deflate=3] = A\ng3[\"A\", chunk=(5,5), blosc=3] = A","category":"page"},{"location":"","page":"Home","title":"Home","text":"Standard compression in HDF5 (\"compress\") corresponds to (\"deflate\") and uses the deflate/zlib algorithm. The deflate algorithm is often more efficient if prefixed by a \"shuffle\" filter. Blosc is generally much faster than deflate – however, reading Blosc-compressed HDF5 files require Blosc to be installed. This is the case for Julia, but often not for vanilla HDF5 distributions that may be used outside Julia. (In this case, the structure of the HDF5 file is still accessible, but compressed datasets cannot be read.) Compression requires chunking, and heuristic chunking is automatically used if you specify compression but don't specify chunking.","category":"page"},{"location":"","page":"Home","title":"Home","text":"It is also possible to write to subsets of an on-disk HDF5 dataset. This is useful to incrementally save to very large datasets you don't want to keep in memory. For example,","category":"page"},{"location":"","page":"Home","title":"Home","text":"dset = d_create(g, \"B\", datatype(Float64), dataspace(1000,100,10), chunk=(100,100,1))\ndset[:,1,1] = rand(1000)","category":"page"},{"location":"","page":"Home","title":"Home","text":"creates a Float64 dataset in the file or group g, with dimensions 1000x100x10, and then writes to just the first 1000 element slice. If you know the typical size of subset reasons you'll be reading/writing, it can be beneficial to set the chunk dimensions appropriately.","category":"page"},{"location":"","page":"Home","title":"Home","text":"More fine-grained control is also available.","category":"page"},{"location":"#Memory-mapping","page":"Home","title":"Memory mapping","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you will frequently be accessing individual elements or small regions of array datasets, it can be substantially more efficient to bypass HDF5 routines and use direct memory mapping. This is possible only under particular conditions: when the dataset is an array of standard \"bits\" types (e.g., Float64 or Int32) and no chunking/compression is being used. You can use the ismmappable function to test whether this is possible; for example,","category":"page"},{"location":"","page":"Home","title":"Home","text":"dset = g[\"x\"]\nif ismmappable(dset)\n    dset = readmmap(dset)\nend\nval = dset[15]","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that readmmap returns an Array rather than an HDF5 object.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note: if you use readmmap on a dataset and subsequently close the file, the array data are still available–-and file continues to be in use–-until all of the arrays are garbage-collected. This is in contrast to standard HDF5 datasets, where closing the file prevents further access to any of the datasets, but the file is also detached and can safely be rewritten immediately.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Under the default allocation-time policy, a newly added ismmappable dataset can only be memory mapped after it has been written to. The following fails:","category":"page"},{"location":"","page":"Home","title":"Home","text":"vec_dset = d_create(g, \"v\", datatype(Float64), dataspace(10_000,1))\nismmappable(vec_dset)    # == true\nvec = readmmap(vec_dset) # throws ErrorException(\"Error mmapping array\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"because although the dataset description has been added, the space within the HDF5 file has not yet actually been allocated (so the file region cannot be memory mapped by the OS). The storage can be allocated by making at least one write:","category":"page"},{"location":"","page":"Home","title":"Home","text":"vec_dset[1,1] = 0.0      # force allocation of /g/v within the file\nvec = readmmap(vec_dset) # and now the memory mapping can succeed","category":"page"},{"location":"","page":"Home","title":"Home","text":"Alternatlively, the policy can be set so that the space is allocated immediately upon creation of the data set with the alloc_time keyword:","category":"page"},{"location":"","page":"Home","title":"Home","text":"mtx_dset = d_create(g, \"M\", datatype(Float64), dataspace(100, 1000),\n                    alloc_time = HDF5.H5D_ALLOC_TIME_EARLY)\nmtx = readmmap(mtx_dset) # succeeds immediately","category":"page"},{"location":"#Supported-data-types","page":"Home","title":"Supported data types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"HDF5.jl knows how to store values of the following types: signed and unsigned integers of 8, 16, 32, and 64 bits, Float32, Float64; Complex versions of these numeric types; Arrays of these numeric types (including complex versions); ASCIIString and UTF8String; and Arrays of these two string types. Arrays of strings are supported using HDF5's variable-length-strings facility. By default Complex numbers are stored as compound types with r and i fields following the h5py convention. When reading data, compound types with matching field names will be loaded as the corresponding Complex julia type. These field names are configurable with the HDF5.set_complex_field_names(real::AbstractString, imag::AbstractString) function and complex support can be completely enabled/disabled with HDF5.enable/disable_complex_support().","category":"page"},{"location":"","page":"Home","title":"Home","text":"For Arrays, note that the array dimensionality is preserved, including 0-length dimensions:","category":"page"},{"location":"","page":"Home","title":"Home","text":"fid[\"zero_vector\"] = zeros(0)\nfid[\"zero_matrix\"] = zeros(0, 0)\nsize(fid[\"zero_vector\"]) # == (0,)\nsize(fid[\"zero_matrix\"]) # == (0, 0)","category":"page"},{"location":"","page":"Home","title":"Home","text":"An exception to this rule is Julia's 0-dimensional Array, which is stored as an HDF5 scalar because there is a value to be preserved:","category":"page"},{"location":"","page":"Home","title":"Home","text":"fid[\"zero_dim_value\"] = fill(1.0π)\nread(fid[\"zero_dim_value\"]) # == 3.141592653589793, != [3.141592653589793]","category":"page"},{"location":"","page":"Home","title":"Home","text":"HDF5 also has the concept of a null array which contains a type but has neither size nor contents, which is represented by the type HDF5.EmptyArray:","category":"page"},{"location":"","page":"Home","title":"Home","text":"fid[\"empty_array\"] = HDF5.EmptyArray{Float32}()\nHDF5.isnull(fid[\"empty_array\"]) # == true\nsize(fid[\"empty_array\"]) # == ()\neltype(fid[\"empty_array\"]) # == Float32","category":"page"},{"location":"","page":"Home","title":"Home","text":"This module also supports HDF5's VLEN, OPAQUE, and REFERENCE types, which can be used to encode more complex types. In general, you need to specify how you want to combine these more advanced facilities to represent more complex data types. For many of the data types in Julia, the JLD module implements support. You can likewise define your own file format if, for example, you need to interact with some external program that has explicit formatting requirements.","category":"page"},{"location":"#Creating-groups-and-attributes","page":"Home","title":"Creating groups and attributes","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Create a new group in the following way:","category":"page"},{"location":"","page":"Home","title":"Home","text":"g = g_create(parent, name)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The named group will be created as a child of the parent.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Attributes can be created using","category":"page"},{"location":"","page":"Home","title":"Home","text":"attrs(parent)[name] = value","category":"page"},{"location":"","page":"Home","title":"Home","text":"where attrs simply indicates that the object referenced by name (a string) is an attribute, not another group or dataset. (Datasets cannot have child datasets, but groups can have either.) value must be a simple type: BitsKinds, strings, and arrays of either of these. The HDF5 standard recommends against storing large objects as attributes.","category":"page"},{"location":"#Getting-information","page":"Home","title":"Getting information","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"name(obj)","category":"page"},{"location":"","page":"Home","title":"Home","text":"will return the full HDF5 pathname of object obj.","category":"page"},{"location":"","page":"Home","title":"Home","text":"keys(g)","category":"page"},{"location":"","page":"Home","title":"Home","text":"returns a string array containing all objects inside group g. These relative pathnames, not absolute pathnames.","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can iterate over the objects in a group, i.e.,","category":"page"},{"location":"","page":"Home","title":"Home","text":"for obj in g\n  data = read(obj)\n  println(data)\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"This gives you a straightforward way of recursively exploring an entire HDF5 file.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you need to know whether group g has a dataset named mydata, you can test that with","category":"page"},{"location":"","page":"Home","title":"Home","text":"if haskey(g, \"mydata\")\n   ...\nend\ntf = haskey(g, \"mydata\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"If instead you want to know whether g has an attribute named myattribute, do it this way:","category":"page"},{"location":"","page":"Home","title":"Home","text":"tf = haskey(attrs(g), \"myattribute\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you have an HDF5 object, and you want to know where it fits in the hierarchy of the file, the following can be useful:","category":"page"},{"location":"","page":"Home","title":"Home","text":"p = parent(obj)     # p is the parent object (usually a group)\nfn = filename(obj)  # fn is a string\ng = root(obj)       # g is the group \"/\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"For array objects (datasets and attributes) the following methods work:","category":"page"},{"location":"","page":"Home","title":"Home","text":"dims = size(dset)\nnd = ndims(dset)\nlen = length(dset)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Objects can be created with properties, and you can query those properties in the following way:","category":"page"},{"location":"","page":"Home","title":"Home","text":"p = get_create_properties(dset)\nchunksz = get_chunk(p)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The simpler syntax chunksz = get_chunk(dset) is also available.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Finally, sometimes you need to be able to conveniently test whether a file is an HDF5 file:","category":"page"},{"location":"","page":"Home","title":"Home","text":"tf = ishdf5(filename)","category":"page"},{"location":"#Mid-level-routines","page":"Home","title":"Mid-level routines","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Sometimes you might want more fine-grained control, which can be achieved using a different set of routines. For example,","category":"page"},{"location":"","page":"Home","title":"Home","text":"g = g_open(parent, name)\ndset = d_open(parent, name[, apl])\nattr = a_open(parent, name)\nt = t_open(parent, name)","category":"page"},{"location":"","page":"Home","title":"Home","text":"These open the named group, dataset, attribute, and committed datatype, respectively. For datasets, apl stands for \"access parameter list\" and provides opportunities for more sophisticated control (see the HDF5 documentation).","category":"page"},{"location":"","page":"Home","title":"Home","text":"New objects can be created in the following ways:","category":"page"},{"location":"","page":"Home","title":"Home","text":"g = g_create(parent, name[, lcpl, dcpl])\ndset = d_create(parent, name, data[, lcpl, dcpl, dapl])\nattr = a_create(parent, name, data)","category":"page"},{"location":"","page":"Home","title":"Home","text":"creates groups, datasets, and attributes without writing any data to them. You can then use write(obj, data) to store the data. The optional property lists allow even more fine-grained control. This syntax uses data to infer the object's \"datatype\" and \"dataspace\"; for the most explicit control, data can be replaced with dtype, dspace, where dtype is an HDF5Datatype and dspace is an HDF5Dataspace.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Analogously, to create committed data types, use","category":"page"},{"location":"","page":"Home","title":"Home","text":"t = t_commit(parent, name, dtype[, lcpl, tcpl, tapl])","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can create and write data in one step,","category":"page"},{"location":"","page":"Home","title":"Home","text":"d_write(parent, name, data[, lcpl, dcpl, dapl])\na_write(parent, name, data)","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can use extendible dimensions,","category":"page"},{"location":"","page":"Home","title":"Home","text":"d = d_create(parent, name, dtype, (dims, max_dims), chunk=(chunk_dims))\nset_dims!(d, new_dims)","category":"page"},{"location":"","page":"Home","title":"Home","text":"where dims is a tuple of integers.  For example","category":"page"},{"location":"","page":"Home","title":"Home","text":"b = d_create(fid, \"b\", Int, ((1000,),(-1,)), chunk=(100,)) #-1 is equivalent to typemax(hsize_t)\nset_dims!(b, (10000,))\nb[1:10000] = collect(1:10000)","category":"page"},{"location":"","page":"Home","title":"Home","text":"when dimensions are reduced, the truncated data is lost.  A maximum dimension of -1 is often referred to as unlimited dimensions, though it is limited by the maximum size of an unsigned integer.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Finally, it's possible to delete objects:","category":"page"},{"location":"","page":"Home","title":"Home","text":"o_delete(parent, name)   # for groups, datasets, and datatypes\na_delete(parent, name)   # for attributes","category":"page"},{"location":"#Low-level-routines","page":"Home","title":"Low-level routines","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Many of the most commonly-used libhdf5 functions have been wrapped. These are not exported, so you need to preface them with HDF5.function to use them. The library follows a consistent convention: for example, libhdf5's H5Adelete is wrapped with a Julia function called h5a_delete. The arguments are exactly as specified in the HDF5 reference manual.","category":"page"},{"location":"","page":"Home","title":"Home","text":"HDF5 is a large library, and the low-level wrap is not complete. However, many of the most-commonly used functions are wrapped, and in general wrapping a new function takes only a single line of code. Users who need additional functionality are encourage to contribute it.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that Julia's HDF5 directly uses the \"2\" interfaces, e.g., H5Dcreate2, so you need to have version 1.8 of the HDF5 library or later.","category":"page"},{"location":"#System-provided-HDF5-libraries","page":"Home","title":"System-provided HDF5 libraries","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Starting from Julia 1.3, the HDF5 binaries are by default downloaded using the HDF5_jll package. To use system-provided HDF5 binaries instead, set the environment variable JULIA_HDF5_LIBRARY_PATH to the HDF5 library path and then run Pkg.build(\"HDF5\"). This is in particular needed for parallel HDF5 support, which is not provided by the HDF5_jll binaries.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For example, you can set JULIA_HDF5_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/hdf5/mpich/ if you're using the system package libhdf5-mpich-dev on Ubuntu 20.04.","category":"page"},{"location":"#Parallel-HDF5","page":"Home","title":"Parallel HDF5","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"It is possible to read and write parallel HDF5 files using MPI. For this, the HDF5 binaries loaded by HDF5.jl must have been compiled with parallel support, and linked to the specific MPI implementation that will be used for parallel I/O.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Parallel-enabled HDF5 libraries are usually included in computing clusters and linked to the available MPI implementations. They are also available via the package manager of a number of Linux distributions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Finally, note that the MPI.jl package is lazy-loaded by HDF5.jl using Requires. In practice, this means that in Julia code, MPI must be imported before HDF5 for parallel functionality to be available.","category":"page"},{"location":"#Setting-up-Parallel-HDF5","page":"Home","title":"Setting-up Parallel HDF5","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The following step-by-step guide assumes one already has access to parallel-enabled HDF5 libraries linked to an existent MPI installation.","category":"page"},{"location":"#.-Using-system-provided-MPI-libraries","page":"Home","title":"1. Using system-provided MPI libraries","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Set the environment variable JULIA_MPI_BINARY=system and then run ]build MPI from Julia. For more control, one can also set the JULIA_MPI_PATH environment variable to the top-level installation directory of the MPI library. See the MPI.jl docs for details.","category":"page"},{"location":"#.-Using-parallel-HDF5-libraries","page":"Home","title":"2. Using parallel HDF5 libraries","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"As detailed in System-provided HDF5 libraries, set the JULIA_HDF5_LIBRARY_PATH environment variable to the directory where the HDF5 libraries compiled with parallel support are found.","category":"page"},{"location":"#.-Loading-MPI-enabled-HDF5","page":"Home","title":"3. Loading MPI-enabled HDF5","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In Julia code, MPI.jl must be loaded before HDF5.jl for MPI functionality to be available:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using MPI\nusing HDF5","category":"page"},{"location":"#Reading-and-writing-data-in-parallel","page":"Home","title":"Reading and writing data in parallel","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A parallel HDF5 file may be opened by passing a MPI.Comm (and optionally a MPI.Info) object to h5open. For instance:","category":"page"},{"location":"","page":"Home","title":"Home","text":"comm = MPI.COMM_WORLD\ninfo = MPI.Info()\nff = h5open(filename, \"w\", comm, info)","category":"page"},{"location":"","page":"Home","title":"Home","text":"MPI-distributed data is typically written by first creating a dataset describing the global dimensions of the data. The following example writes a 10 × Nproc array distributed over Nproc MPI processes.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Nproc = MPI.Comm_size(comm)\nmyrank = MPI.Comm_rank(comm)\nM = 10\nA = fill(myrank, M)  # local data\ndims = (M, Nproc)    # dimensions of global data\n\n# Create dataset\ndset = d_create(ff, \"/data\", datatype(eltype(A)), dataspace(dims))\n\n# Write local data\ndset[:, myrank + 1] = A","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that all MPI processes must call d_create with the same arguments.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Sometimes, it may be more efficient to write data in chunks, so that each process writes to a separate chunk of the file. This is especially the case when data is uniformly distributed among MPI processes. In this example, this can be achieved by passing chunk=(M, 1) to d_create.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For better performance, it is sometimes preferable to perform collective I/O when reading and writing datasets in parallel. This is achieved by passing dxpl_mpio=HDF5.H5FD_MPIO_COLLECTIVE to d_create. See also the HDF5 docs.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A few more examples are available in test/mpio.jl.","category":"page"},{"location":"#Details","page":"Home","title":"Details","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Julia, like Fortran and Matlab, stores arrays in column-major order. HDF5 uses C's row-major order, and consequently every array's dimensions are inverted compared to what you see with tools like h5dump. This is the same convention as for the Fortran and Matlab HDF5 interfaces. The advantage is that no data rearrangement takes place when reading or writing.","category":"page"},{"location":"#API-Reference","page":"Home","title":"API Reference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Below we include a limited number of API references. Note not all of these are public interfaces, thus proceed with caution.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [HDF5]","category":"page"},{"location":"#HDF5.SHOW_TREE","page":"Home","title":"HDF5.SHOW_TREE","text":"SHOW_TREE = Ref{Bool}(true)\n\nConfigurable option to control whether the default show for HDF5 objects is printed using show_tree or not.\n\n\n\n\n\n","category":"constant"},{"location":"#HDF5.SHOW_TREE_ICONS","page":"Home","title":"HDF5.SHOW_TREE_ICONS","text":"SHOW_TREE_ICONS = Ref{Bool}(true)\n\nConfigurable option to control whether emoji icons (true) or a plain-text annotation (false) is used to indicate the object type by show_tree.\n\n\n\n\n\n","category":"constant"},{"location":"#Base.isopen-Tuple{HDF5.File}","page":"Home","title":"Base.isopen","text":"isopen(obj::HDF5.File)\n\nReturns true if obj has not been closed, false if it has been closed.\n\n\n\n\n\n","category":"method"},{"location":"#HDF5.create_external-Tuple{Union{HDF5.File, HDF5.Group},Any,Any,Any}","page":"Home","title":"HDF5.create_external","text":"create_external(source::Union{HDF5.File, HDF5.Group}, source_relpath, target_filename, target_path;\n                lcpl_id=HDF5.H5P_DEFAULT, lapl_id=HDF5.H5P.DEFAULT)\n\nCreate an external link such that source[source_relpath] points to target_path within the file with path target_filename; Calls [H5Lcreate_external](https://www.hdfgroup.org/HDF5/doc/RM/RM_H5L.html#Link-CreateExternal).\n\n\n\n\n\n","category":"method"},{"location":"#HDF5.get_datasets-Tuple{HDF5.File}","page":"Home","title":"HDF5.get_datasets","text":"get_datasets(file::HDF5.File) -> datasets::Vector{HDF5.Dataset}\n\nGet all the datasets in an hdf5 file without loading the data.\n\n\n\n\n\n","category":"method"},{"location":"#HDF5.get_dims-Tuple{HDF5.Dataset}","page":"Home","title":"HDF5.get_dims","text":"get_dims(dset::HDF5.Dataset)\n\nGet the array dimensions from a dataset and return a tuple of dims and maxdims.\n\n\n\n\n\n","category":"method"},{"location":"#HDF5.h5open","page":"Home","title":"HDF5.h5open","text":"h5open(filename, [mode=\"r\"], comm::MPI.Comm, [info::MPI.Info]; pv...)\n\nOpen or create a parallel HDF5 file using the MPI-IO driver.\n\nEquivalent to h5open(filename, mode; fapl_mpio=(comm, info), pv...). Throws an informative error if the loaded HDF5 libraries do not include parallel support.\n\nSee the HDF5 docs for details on the comm and info arguments.\n\n\n\n\n\n","category":"function"},{"location":"#HDF5.h5open-2","page":"Home","title":"HDF5.h5open","text":"h5open(filename::AbstractString, mode::AbstractString=\"r\"; swmr=false, pv...)\n\nOpen or create an HDF5 file where mode is one of:\n\n\"r\"  read only\n\"r+\" read and write\n\"cw\" read and write, create file if not existing, do not truncate\n\"w\"  read and write, create a new file (destroys any existing contents)\n\nPass swmr=true to enable (Single Writer Multiple Reader) SWMR write access for \"w\" and \"r+\", or SWMR read access for \"r\".\n\n\n\n\n\n","category":"function"},{"location":"#HDF5.h5open-Tuple{Function,Vararg{Any,N} where N}","page":"Home","title":"HDF5.h5open","text":"function h5open(f::Function, args...; swmr=false, pv...)\n\nApply the function f to the result of h5open(args...;kwargs...) and close the resulting HDF5.File upon completion. For example with a do block:\n\nh5open(\"foo.h5\",\"w\") do h5\n    h5[\"foo\"]=[1,2,3]\nend\n\n\n\n\n\n","category":"method"},{"location":"#HDF5.has_parallel-Tuple{}","page":"Home","title":"HDF5.has_parallel","text":"has_parallel()\n\nReturns true if the HDF5 libraries were compiled with parallel support, and if parallel functionality was loaded into HDF5.jl.\n\nFor the second condition to be true, MPI.jl must be imported before HDF5.jl.\n\n\n\n\n\n","category":"method"},{"location":"#HDF5.ishdf5-Tuple{AbstractString}","page":"Home","title":"HDF5.ishdf5","text":"ishdf5(name::AbstractString)\n\nReturns true if name is a path to a valid hdf5 file, false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"#HDF5.set_dims!-Tuple{HDF5.Dataset,Tuple{Vararg{Int64,N}} where N}","page":"Home","title":"HDF5.set_dims!","text":"set_dims!(dset::HDF5.Dataset, new_dims::Dims)\n\nChange the current dimensions of a dataset to new_dims, limited by max_dims = get_dims(dset)[2]. Reduction is possible and leads to loss of truncated data.\n\n\n\n\n\n","category":"method"},{"location":"#HDF5.start_swmr_write-Tuple{HDF5.File}","page":"Home","title":"HDF5.start_swmr_write","text":"start_swmr_write(h5::HDF5.File)\n\nStart Single Reader Multiple Writer (SWMR) writing mode. See SWMR documentation.\n\n\n\n\n\n","category":"method"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"<!-- This file is auto-generated and should not be manually editted. To update, run the\ngen/gen_wrappers.jl script -->","category":"page"},{"location":"api_bindings/#Low-level-library-bindings","page":"Low-level library bindings","title":"Low-level library bindings","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"At the lowest level, HDF5.jl operates by calling the public API of the HDF5 shared library through a set of ccall wrapper functions. This page documents the function names and nominal C argument types of the API which have bindings in this package. Note that in many cases, high-level data types are valid arguments through automatic ccall conversions. For instance, HDF5Datatype objects will be automatically converted to their hid_t ID by Julia's cconvert+unsafe_convert ccall rules.","category":"page"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"There are additional helper wrappers (often for out-argument functions) which are not documented here.","category":"page"},{"location":"api_bindings/#[H5](https://portal.hdfgroup.org/display/HDF5/Library)-—-General-Library-Functions","page":"Low-level library bindings","title":"H5 — General Library Functions","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5_close()\nh5_dont_atexit()\nh5_free_memory(buf::Ptr{Cvoid})\nh5_garbage_collect()\nh5_get_libversion(majnum::Ref{Cuint}, minnum::Ref{Cuint}, relnum::Ref{Cuint})\nh5_is_library_threadsafe(is_ts::Ref{Cuint})\nh5_open()\nh5_set_free_list_limits(reg_global_lim::Cint, reg_list_lim::Cint, arr_global_lim::Cint, arr_list_lim::Cint, blk_global_lim::Cint, blk_list_lim::Cint)","category":"page"},{"location":"api_bindings/#[H5A](https://portal.hdfgroup.org/display/HDF5/Attributes)-—-Attribute-Interface","page":"Low-level library bindings","title":"H5A — Attribute Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5a_close(id::hid_t)\nh5a_create(loc_id::hid_t, pathname::Ptr{UInt8}, type_id::hid_t, space_id::hid_t, acpl_id::hid_t, aapl_id::hid_t)\nh5a_create_by_name(loc_id::hid_t, obj_name::Ptr{UInt8}, attr_name::Ptr{UInt8}, type_id::hid_t, space_id::hid_t, acpl_id::hid_t, aapl_id::hid_t, lapl_id::hid_t)\nh5a_delete(loc_id::hid_t, attr_name::Ptr{UInt8})\nh5a_delete_by_idx(loc_id::hid_t, obj_name::Ptr{UInt8}, idx_type::Cint, order::Cint, n::hsize_t, lapl_id::hid_t)\nh5a_delete_by_name(loc_id::hid_t, obj_name::Ptr{UInt8}, attr_name::Ptr{UInt8}, lapl_id::hid_t)\nh5a_exists(obj_id::hid_t, attr_name::Ptr{UInt8})\nh5a_exists_by_name(loc_id::hid_t, obj_name::Ptr{UInt8}, attr_name::Ptr{UInt8}, lapl_id::hid_t)\nh5a_get_create_plist(attr_id::hid_t)\nh5a_get_name(attr_id::hid_t, buf_size::Csize_t, buf::Ptr{UInt8})\nh5a_get_name_by_idx(loc_id::hid_t, obj_name::Cstring, index_type::Cint, order::Cint, idx::hsize_t, name::Ptr{UInt8}, size::Csize_t, lapl_id::hid_t)\nh5a_get_space(attr_id::hid_t)\nh5a_get_type(attr_id::hid_t)\nh5a_open(obj_id::hid_t, pathname::Ptr{UInt8}, aapl_id::hid_t)\nh5a_read(attr_id::hid_t, mem_type_id::hid_t, buf::Ptr{Cvoid})\nh5a_write(attr_hid::hid_t, mem_type_id::hid_t, buf::Ptr{Cvoid})","category":"page"},{"location":"api_bindings/#[H5D](https://portal.hdfgroup.org/display/HDF5/Datasets)-—-Dataset-Interface","page":"Low-level library bindings","title":"H5D — Dataset Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5d_close(dataset_id::hid_t)\nh5d_create(loc_id::hid_t, pathname::Ptr{UInt8}, dtype_id::hid_t, space_id::hid_t, lcpl_id::hid_t, dcpl_id::hid_t, dapl_id::hid_t)\nh5d_flush(dataset_id::hid_t)\nh5d_get_access_plist(dataset_id::hid_t)\nh5d_get_create_plist(dataset_id::hid_t)\nh5d_get_offset(dataset_id::hid_t)\nh5d_get_space(dataset_id::hid_t)\nh5d_get_type(dataset_id::hid_t)\nh5d_open(loc_id::hid_t, pathname::Ptr{UInt8}, dapl_id::hid_t)\nh5d_read(dataset_id::hid_t, mem_type_id::hid_t, mem_space_id::hid_t, file_space_id::hid_t, xfer_plist_id::hid_t, buf::Ptr{Cvoid})\nh5d_refresh(dataset_id::hid_t)\nh5d_set_extent(dataset_id::hid_t, new_dims::Ptr{hsize_t})\nh5d_vlen_get_buf_size(dset_id::hid_t, type_id::hid_t, space_id::hid_t, buf::Ptr{hsize_t})\nh5d_vlen_reclaim(type_id::hid_t, space_id::hid_t, plist_id::hid_t, buf::Ptr{Cvoid})\nh5d_write(dataset_id::hid_t, mem_type_id::hid_t, mem_space_id::hid_t, file_space_id::hid_t, xfer_plist_id::hid_t, buf::Ptr{Cvoid})","category":"page"},{"location":"api_bindings/#[H5E](https://portal.hdfgroup.org/display/HDF5/ErrorHandling)-—-Error-Interface","page":"Low-level library bindings","title":"H5E — Error Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5e_get_auto(estack_id::hid_t, func::Ref{Ptr{Cvoid}}, client_data::Ref{Ptr{Cvoid}})\nh5e_set_auto(estack_id::hid_t, func::Ptr{Cvoid}, client_data::Ptr{Cvoid})","category":"page"},{"location":"api_bindings/#[H5F](https://portal.hdfgroup.org/display/HDF5/Files)-—-File-Interface","page":"Low-level library bindings","title":"H5F — File Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5f_close(file_id::hid_t)\nh5f_create(pathname::Ptr{UInt8}, flags::Cuint, fcpl_id::hid_t, fapl_id::hid_t)\nh5f_flush(object_id::hid_t, scope::Cint)\nh5f_get_access_plist(file_id::hid_t)\nh5f_get_create_plist(file_id::hid_t)\nh5f_get_intent(file_id::hid_t, intent::Ptr{Cuint})\nh5f_get_name(obj_id::hid_t, buf::Ptr{UInt8}, buf_size::Csize_t)\nh5f_get_obj_count(file_id::hid_t, types::Cuint)\nh5f_get_obj_ids(file_id::hid_t, types::Cuint, max_objs::Csize_t, obj_id_list::Ptr{hid_t})\nh5f_get_vfd_handle(file_id::hid_t, fapl_id::hid_t, file_handle::Ref{Ptr{Cvoid}})\nh5f_is_hdf5(pathname::Cstring)\nh5f_open(pathname::Cstring, flags::Cuint, fapl_id::hid_t)\nh5f_start_swmr_write(id::hid_t)","category":"page"},{"location":"api_bindings/#[H5G](https://portal.hdfgroup.org/display/HDF5/Groups)-—-Group-Interface","page":"Low-level library bindings","title":"H5G — Group Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5g_close(group_id::hid_t)\nh5g_create(loc_id::hid_t, pathname::Ptr{UInt8}, lcpl_id::hid_t, gcpl_id::hid_t, gapl_id::hid_t)\nh5g_get_create_plist(group_id::hid_t)\nh5g_get_info(group_id::hid_t, buf::Ptr{H5G_info_t})\nh5g_get_num_objs(loc_id::hid_t, num_obj::Ptr{hsize_t})\nh5g_get_objname_by_idx(loc_id::hid_t, idx::hsize_t, pathname::Ptr{UInt8}, size::Csize_t)\nh5g_open(loc_id::hid_t, pathname::Ptr{UInt8}, gapl_id::hid_t)","category":"page"},{"location":"api_bindings/#[H5I](https://portal.hdfgroup.org/display/HDF5/Identifiers)-—-Identifier-Interface","page":"Low-level library bindings","title":"H5I — Identifier Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5i_dec_ref(obj_id::hid_t)\nh5i_get_file_id(obj_id::hid_t)\nh5i_get_name(obj_id::hid_t, buf::Ptr{UInt8}, buf_size::Csize_t)\nh5i_get_ref(obj_id::hid_t)\nh5i_get_type(obj_id::hid_t)\nh5i_inc_ref(obj_id::hid_t)\nh5i_is_valid(obj_id::hid_t)","category":"page"},{"location":"api_bindings/#[H5L](https://portal.hdfgroup.org/display/HDF5/Links)-—-Link-Interface","page":"Low-level library bindings","title":"H5L — Link Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5l_create_external(target_file_name::Ptr{UInt8}, target_obj_name::Ptr{UInt8}, link_loc_id::hid_t, link_name::Ptr{UInt8}, lcpl_id::hid_t, lapl_id::hid_t)\nh5l_create_hard(obj_loc_id::hid_t, obj_name::Ptr{UInt8}, link_loc_id::hid_t, link_name::Ptr{UInt8}, lcpl_id::hid_t, lapl_id::hid_t)\nh5l_create_soft(target_path::Ptr{UInt8}, link_loc_id::hid_t, link_name::Ptr{UInt8}, lcpl_id::hid_t, lapl_id::hid_t)\nh5l_delete(obj_id::hid_t, pathname::Ptr{UInt8}, lapl_id::hid_t)\nh5l_exists(loc_id::hid_t, pathname::Ptr{UInt8}, lapl_id::hid_t)\nh5l_get_info(link_loc_id::hid_t, link_name::Ptr{UInt8}, link_buf::Ptr{H5L_info_t}, lapl_id::hid_t)\nh5l_get_name_by_idx(loc_id::hid_t, group_name::Ptr{UInt8}, index_field::Cint, order::Cint, n::hsize_t, name::Ptr{UInt8}, size::Csize_t, lapl_id::hid_t)","category":"page"},{"location":"api_bindings/#[H5O](https://portal.hdfgroup.org/display/HDF5/Objects)-—-Object-Interface","page":"Low-level library bindings","title":"H5O — Object Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5o_close(object_id::hid_t)\nh5o_copy(src_loc_id::hid_t, src_name::Ptr{UInt8}, dst_loc_id::hid_t, dst_name::Ptr{UInt8}, ocpypl_id::hid_t, lcpl_id::hid_t)\nh5o_get_info(object_id::hid_t, buf::Ptr{H5O_info_t})\nh5o_open(loc_id::hid_t, pathname::Ptr{UInt8}, lapl_id::hid_t)\nh5o_open_by_addr(loc_id::hid_t, addr::haddr_t)\nh5o_open_by_idx(loc_id::hid_t, group_name::Ptr{UInt8}, index_type::Cint, order::Cint, n::hsize_t, lapl_id::hid_t)","category":"page"},{"location":"api_bindings/#[H5P](https://portal.hdfgroup.org/display/HDF5/PropertyLists)-—-Property-Interface","page":"Low-level library bindings","title":"H5P — Property Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5p_close(id::hid_t)\nh5p_create(cls_id::hid_t)\nh5p_get_alignment(fapl_id::hid_t, threshold::Ref{hsize_t}, alignment::Ref{hsize_t})\nh5p_get_alloc_time(plist_id::hid_t, alloc_time::Ptr{Cint})\nh5p_get_char_encoding(plist_id::hid_t, encoding::Ref{Cint})\nh5p_get_chunk(plist_id::hid_t, n_dims::Cint, dims::Ptr{hsize_t})\nh5p_get_class_name(pcid::hid_t)\nh5p_get_create_intermediate_group(lcpl_id::hid_t, crt_intermed_group::Ref{Cuint})\nh5p_get_driver(plist_id::hid_t)\nh5p_get_driver_info(plist_id::hid_t)\nh5p_get_dxpl_mpio(dxpl_id::hid_t, xfer_mode::Ptr{Cint})\nh5p_get_fapl_mpio32(fapl_id::hid_t, comm::Ptr{Hmpih32}, info::Ptr{Hmpih32})\nh5p_get_fapl_mpio64(fapl_id::hid_t, comm::Ptr{Hmpih64}, info::Ptr{Hmpih64})\nh5p_get_fclose_degree(fapl_id::hid_t, fc_degree::Ref{Cint})\nh5p_get_filter_by_id(plist_id::hid_t, filter_id::H5Z_filter_t, flags::Ref{Cuint}, cd_nelmts::Ref{Csize_t}, cd_values::Ptr{Cuint}, namelen::Csize_t, name::Ptr{UInt8}, filter_config::Ptr{Cuint})\nh5p_get_layout(plist_id::hid_t)\nh5p_get_libver_bounds(fapl_id::hid_t, low::Ref{Cint}, high::Ref{Cint})\nh5p_get_local_heap_size_hint(plist_id::hid_t, size_hint::Ref{Csize_t})\nh5p_get_obj_track_times(plist_id::hid_t, track_times::Ref{UInt8})\nh5p_get_userblock(plist_id::hid_t, len::Ptr{hsize_t})\nh5p_modify_filter(plist_id::hid_t, filter_id::H5Z_filter_t, flags::Cuint, cd_nelmts::Csize_t, cd_values::Ptr{Cuint})\nh5p_set_alignment(plist_id::hid_t, threshold::hsize_t, alignment::hsize_t)\nh5p_set_alloc_time(plist_id::hid_t, alloc_time::Cint)\nh5p_set_char_encoding(plist_id::hid_t, encoding::Cint)\nh5p_set_chunk(plist_id::hid_t, ndims::Cint, dims::Ptr{hsize_t})\nh5p_set_chunk_cache(dapl_id::hid_t, rdcc_nslots::Csize_t, rdcc_nbytes::Csize_t, rdcc_w0::Cdouble)\nh5p_set_create_intermediate_group(plist_id::hid_t, setting::Cuint)\nh5p_set_deflate(plist_id::hid_t, setting::Cuint)\nh5p_set_dxpl_mpio(dxpl_id::hid_t, xfer_mode::Cint)\nh5p_set_external(plist_id::hid_t, name::Ptr{UInt8}, offset::Int, size::Csize_t)\nh5p_set_fapl_mpio32(fapl_id::hid_t, comm::Hmpih32, info::Hmpih32)\nh5p_set_fapl_mpio64(fapl_id::hid_t, comm::Hmpih64, info::Hmpih64)\nh5p_set_fclose_degree(plist_id::hid_t, fc_degree::Cint)\nh5p_set_filter(plist_id::hid_t, filter_id::H5Z_filter_t, flags::Cuint, cd_nelmts::Csize_t, cd_values::Ptr{Cuint})\nh5p_set_layout(plist_id::hid_t, setting::Cint)\nh5p_set_libver_bounds(fapl_id::hid_t, low::Cint, high::Cint)\nh5p_set_local_heap_size_hint(plist_id::hid_t, size_hint::Csize_t)\nh5p_set_obj_track_times(plist_id::hid_t, track_times::UInt8)\nh5p_set_shuffle(plist_id::hid_t)\nh5p_set_userblock(plist_id::hid_t, len::hsize_t)\nh5p_set_virtual(dcpl_id::hid_t, vspace_id::hid_t, src_file_name::Ptr{UInt8}, src_dset_name::Ptr{UInt8}, src_space_id::hid_t)","category":"page"},{"location":"api_bindings/#[H5R](https://portal.hdfgroup.org/display/HDF5/References)-—-Reference-Interface","page":"Low-level library bindings","title":"H5R — Reference Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5r_create(ref::Ptr{Cvoid}, loc_id::hid_t, pathname::Ptr{UInt8}, ref_type::Cint, space_id::hid_t)\nh5r_dereference(obj_id::hid_t, oapl_id::hid_t, ref_type::Cint, ref::Ptr{Cvoid})\nh5r_get_obj_type(loc_id::hid_t, ref_type::Cint, ref::Ptr{Cvoid}, obj_type::Ptr{Cint})\nh5r_get_region(loc_id::hid_t, ref_type::Cint, ref::Ptr{Cvoid})","category":"page"},{"location":"api_bindings/#[H5S](https://portal.hdfgroup.org/display/HDF5/Dataspaces)-—-Dataspace-Interface","page":"Low-level library bindings","title":"H5S — Dataspace Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5s_close(space_id::hid_t)\nh5s_copy(space_id::hid_t)\nh5s_create(class::Cint)\nh5s_create_simple(rank::Cint, current_dims::Ptr{hsize_t}, maximum_dims::Ptr{hsize_t})\nh5s_get_select_npoints(space_id::hid_t)\nh5s_get_simple_extent_dims(space_id::hid_t, dims::Ptr{hsize_t}, maxdims::Ptr{hsize_t})\nh5s_get_simple_extent_ndims(space_id::hid_t)\nh5s_get_simple_extent_type(space_id::hid_t)\nh5s_is_simple(space_id::hid_t)\nh5s_select_hyperslab(dspace_id::hid_t, seloper::Cint, start::Ptr{hsize_t}, stride::Ptr{hsize_t}, count::Ptr{hsize_t}, block::Ptr{hsize_t})","category":"page"},{"location":"api_bindings/#[H5T](https://portal.hdfgroup.org/display/HDF5/Datatypes)-—-Datatype-Interface","page":"Low-level library bindings","title":"H5T — Datatype Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5t_array_create(basetype_id::hid_t, ndims::Cuint, sz::Ptr{hsize_t})\nh5t_close(dtype_id::hid_t)\nh5t_commit(loc_id::hid_t, name::Ptr{UInt8}, dtype_id::hid_t, lcpl_id::hid_t, tcpl_id::hid_t, tapl_id::hid_t)\nh5t_committed(dtype_id::hid_t)\nh5t_copy(dtype_id::hid_t)\nh5t_create(class_id::Cint, sz::Csize_t)\nh5t_equal(dtype_id1::hid_t, dtype_id2::hid_t)\nh5t_get_array_dims(dtype_id::hid_t, dims::Ptr{hsize_t})\nh5t_get_array_ndims(dtype_id::hid_t)\nh5t_get_class(dtype_id::hid_t)\nh5t_get_cset(dtype_id::hid_t)\nh5t_get_ebias(dtype_id::hid_t)\nh5t_get_fields(dtype_id::hid_t, spos::Ref{Csize_t}, epos::Ref{Csize_t}, esize::Ref{Csize_t}, mpos::Ref{Csize_t}, msize::Ref{Csize_t})\nh5t_get_member_class(dtype_id::hid_t, index::Cuint)\nh5t_get_member_index(dtype_id::hid_t, membername::Ptr{UInt8})\nh5t_get_member_name(type_id::hid_t, index::Cuint)\nh5t_get_member_offset(dtype_id::hid_t, index::Cuint)\nh5t_get_member_type(dtype_id::hid_t, index::Cuint)\nh5t_get_native_type(dtype_id::hid_t, direction::Cint)\nh5t_get_nmembers(dtype_id::hid_t)\nh5t_get_sign(dtype_id::hid_t)\nh5t_get_size(dtype_id::hid_t)\nh5t_get_strpad(dtype_id::hid_t)\nh5t_get_super(dtype_id::hid_t)\nh5t_get_tag(type_id::hid_t)\nh5t_insert(dtype_id::hid_t, fieldname::Ptr{UInt8}, offset::Csize_t, field_id::hid_t)\nh5t_is_variable_str(type_id::hid_t)\nh5t_lock(type_id::hid_t)\nh5t_open(loc_id::hid_t, name::Ptr{UInt8}, tapl_id::hid_t)\nh5t_set_cset(dtype_id::hid_t, cset::Cint)\nh5t_set_ebias(dtype_id::hid_t, ebias::Csize_t)\nh5t_set_fields(dtype_id::hid_t, spos::Csize_t, epos::Csize_t, esize::Csize_t, mpos::Csize_t, msize::Csize_t)\nh5t_set_precision(dtype_id::hid_t, sz::Csize_t)\nh5t_set_size(dtype_id::hid_t, sz::Csize_t)\nh5t_set_strpad(dtype_id::hid_t, sz::Cint)\nh5t_vlen_create(base_type_id::hid_t)","category":"page"},{"location":"api_bindings/#[H5Z](https://portal.hdfgroup.org/display/HDF5/Filters)-—-Filter-Interface","page":"Low-level library bindings","title":"H5Z — Filter Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5z_register(filter_class::Ref{H5Z_class_t})","category":"page"},{"location":"api_bindings/#[H5DO](https://portal.hdfgroup.org/display/HDF5/Optimizations)-—-Optimized-Functions-Interface","page":"Low-level library bindings","title":"H5DO — Optimized Functions Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5do_append(dset_id::hid_t, dxpl_id::hid_t, index::Cuint, num_elem::hsize_t, memtype::hid_t, buffer::Ptr{Cvoid})\nh5do_write_chunk(dset_id::hid_t, dxpl_id::hid_t, filter_mask::Int32, offset::Ptr{hsize_t}, bufsize::Csize_t, buf::Ptr{Cvoid})","category":"page"},{"location":"api_bindings/#[H5DS](https://portal.hdfgroup.org/display/HDF5/DimensionScales)-—-Dimension-Scale-Interface","page":"Low-level library bindings","title":"H5DS — Dimension Scale Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5ds_attach_scale(did::hid_t, dsid::hid_t, idx::Cuint)\nh5ds_detach_scale(did::hid_t, dsid::hid_t, idx::Cuint)\nh5ds_get_label(did::hid_t, idx::Cuint, label::Ptr{UInt8}, size::hsize_t)\nh5ds_get_num_scales(did::hid_t, idx::Cuint)\nh5ds_get_scale_name(did::hid_t, name::Ptr{UInt8}, size::Csize_t)\nh5ds_is_attached(did::hid_t, dsid::hid_t, idx::Cuint)\nh5ds_is_scale(did::hid_t)\nh5ds_set_label(did::hid_t, idx::Cuint, label::Ref{UInt8})\nh5ds_set_scale(dsid::hid_t, dimname::Ptr{UInt8})","category":"page"},{"location":"api_bindings/#[H5LT](https://portal.hdfgroup.org/display/HDF5/Lite)-—-Lite-Interface","page":"Low-level library bindings","title":"H5LT — Lite Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5lt_dtype_to_text(datatype::hid_t, str::Ptr{UInt8}, lang_type::Cint, len::Ref{Csize_t})","category":"page"},{"location":"api_bindings/#[H5TB](https://portal.hdfgroup.org/display/HDF5/Tables)-—-Table-Interface","page":"Low-level library bindings","title":"H5TB — Table Interface","text":"","category":"section"},{"location":"api_bindings/","page":"Low-level library bindings","title":"Low-level library bindings","text":"h5tb_get_field_info(loc_id::hid_t, table_name::Ptr{UInt8}, field_names::Ptr{Ptr{UInt8}}, field_sizes::Ptr{UInt8}, field_offsets::Ptr{UInt8}, type_size::Ptr{UInt8})","category":"page"}]
}
